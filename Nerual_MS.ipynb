{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0ef0624",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function, division\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m tf\u001b[38;5;241m.\u001b[39mdisable_v2_behavior()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/tensorflow/__init__.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/tensorflow/python/__init__.py:36\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py:26\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m self_check\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Cleanup antipattern: import for side effects.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mself_check\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreload_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m   \u001b[38;5;66;03m# This import is expected to fail if there is an explicit shared object\u001b[39;00m\n\u001b[1;32m     32\u001b[0m   \u001b[38;5;66;03m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/tensorflow/python/platform/self_check.py:63\u001b[0m, in \u001b[0;36mpreload_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     51\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find the DLL(s) \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m. TensorFlow requires that these DLLs \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe installed in a directory that is named in your \u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m           \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing))\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m   \u001b[38;5;66;03m# Load a library that performs CPU feature guard checking.  Doing this here\u001b[39;00m\n\u001b[1;32m     60\u001b[0m   \u001b[38;5;66;03m# as a preload check makes it more likely that we detect any CPU feature\u001b[39;00m\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;66;03m# incompatibilities before we trigger them (which would typically result in\u001b[39;00m\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;66;03m# SIGILL).\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_cpu_feature_guard\n\u001b[1;32m     64\u001b[0m   _pywrap_cpu_feature_guard\u001b[38;5;241m.\u001b[39mInfoAboutUnusedCPUFeatures()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcbbeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n",
    "[*tf.config.list_physical_devices()]\n",
    "# %pip install tensorflow-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cfe982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 17:19:44.245586: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-04-08 17:19:44.245620: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775fbad8",
   "metadata": {},
   "source": [
    "ShapeLayer: in code_PCM why value are integer not binary? if value must represent connectivity between code node(in column) and value node(in row), binary is enough to represent connectivity\n",
    "\n",
    "GitHub Copilot: # LDPC Protograph Matrix Integer Values Explained\n",
    "\n",
    "You're making an excellent observation. In standard LDPC codes, the parity check matrix is indeed binary (0/1). However, in this implementation, the initial `code_PCM` contains integer values for a specific reason: this is using a **protograph-based LDPC** code construction.\n",
    "\n",
    "## Why Integer Values Instead of Binary?\n",
    "\n",
    "The integer values in the original PCM serve a dual purpose:\n",
    "- `-1`: Represents no connection between nodes\n",
    "- Positive integers (1, 2, 3, etc.): Represent both a connection AND a **cyclic shift parameter**\n",
    "\n",
    "## How These Values Are Used\n",
    "\n",
    "1. **For Connectivity Matrices** (like `W_odd2even`, `W_even2odd`):\n",
    "   ```python\n",
    "   # The PCM is converted to binary (0/1)\n",
    "   for i in range(0, code_PCM.shape[0]):\n",
    "       for j in range(0, code_PCM.shape[1]):\n",
    "           if (code_PCM[i, j] == -1):\n",
    "               code_PCM[i, j] = 0  # No connection\n",
    "           else:\n",
    "               code_PCM[i, j] = 1  # Connection exists\n",
    "   ```\n",
    "\n",
    "2. **For Protograph Lifting** (creating the actual LDPC code):\n",
    "   ```python\n",
    "   # Original integer values used for cyclic shifts\n",
    "   if (code_PCM1[i, j] != -1):\n",
    "       Lift_num = code_PCM1[i, j] % Z_array[t]  # Get cyclic shift amount\n",
    "       for h in range(0, Z_array[t], 1):\n",
    "           Lift_M1[k * Z_array[t] + h, k * Z_array[t] + (h + Lift_num) % Z_array[t]] = 1\n",
    "   ```\n",
    "\n",
    "## Key Insight\n",
    "\n",
    "The implementation maintains two versions of the matrix:\n",
    "1. `code_PCM` - Binary version for neural network connectivity \n",
    "2. `Ldpc_PCM` - Original integer version for lifting operations\n",
    "\n",
    "This is why the original matrices are kept as:\n",
    "```python\n",
    "Ldpc_PCM = [code_PCM0, code_PCM1, code_PCM2, code_PCM1]\n",
    "```\n",
    "\n",
    "This approach is standard in protograph LDPC codes, where the specific shift values enable creating diverse expanded matrices with good properties while maintaining a compact base representation.\n",
    "\n",
    "ShapeLayer: what is protograph based ldpc and what does that work\n",
    "\n",
    "GitHub Copilot: # Protograph-Based LDPC Codes: A Structured Approach to Error Correction\n",
    "\n",
    "Protograph-based LDPC (Low-Density Parity-Check) codes are a powerful class of error-correcting codes that use a small template graph to generate larger, structured codes with excellent performance characteristics.\n",
    "\n",
    "## What is a Protograph?\n",
    "\n",
    "A protograph is a relatively small \"blueprint\" or \"template\" graph that defines the basic structure of the LDPC code:\n",
    "\n",
    "- It's represented as a small base matrix (like `code_PCM0` in your code)\n",
    "- Values in this matrix have dual meaning:\n",
    "  - `-1`: No connection between nodes\n",
    "  - Positive integers (1, 2, 3...): Both indicate a connection AND specify a shift parameter\n",
    "\n",
    "## How Protograph-Based LDPC Codes Work\n",
    "\n",
    "These codes are constructed through a process called \"lifting\" or \"copy-and-permute\":\n",
    "\n",
    "1. **Start with a protograph base matrix** (small matrix with integer values)\n",
    "2. **Make Z copies** of this base graph (Z is the lifting factor)\n",
    "3. **Connect these copies** according to specific shift patterns defined by the integers in the protograph\n",
    "\n",
    "In your code, this lifting process is implemented here:\n",
    "\n",
    "```python\n",
    "# For each connection in the protograph\n",
    "if (code_PCM1[i, j] != -1):\n",
    "    # Calculate the cyclic shift amount from the protograph value\n",
    "    Lift_num = code_PCM1[i, j] % Z_array[t]\n",
    "    # Create a shifted identity submatrix\n",
    "    for h in range(0, Z_array[t], 1):\n",
    "        Lift_M1[k * Z_array[t] + h, k * Z_array[t] + (h + Lift_num) % Z_array[t]] = 1\n",
    "```\n",
    "\n",
    "## Advantages of Protograph-Based LDPC\n",
    "\n",
    "1. **Structured design** - Makes hardware implementation more efficient\n",
    "2. **Scalability** - Same protograph can generate codes of different lengths by changing Z\n",
    "3. **Design flexibility** - Different protographs for different channel conditions\n",
    "4. **Excellent performance** - Can approach Shannon capacity with proper design\n",
    "5. **Implementation efficiency** - Matrix operations can exploit the structure\n",
    "\n",
    "## In Your Neural Decoder Implementation\n",
    "\n",
    "Your code uses multiple protographs with different lifting factors:\n",
    "- Four base protographs (`code_PCM0`, `code_PCM1`, `code_PCM2`)\n",
    "- Four lifting factors (Z = 16, 3, 10, 6)\n",
    "\n",
    "The integer values in the original matrices enable the cyclic shift operation during lifting, while the binary (0/1) version provides the basic connectivity pattern for the neural network's message passing framework.\n",
    "\n",
    "The neural network then learns to optimize the message passing on this structured graph, leveraging the inherent structural advantages of protograph-based LDPC codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9435e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_PCM0 = np.loadtxt(\"./BaseGraph/BaseGraph2_Set0.txt\", int, delimiter='\t')\n",
    "code_PCM1 = np.loadtxt(\"./BaseGraph/BaseGraph2_Set1.txt\", int, delimiter='\t')\n",
    "code_PCM2 = np.loadtxt(\"./BaseGraph/BaseGraph2_Set2.txt\", int, delimiter='\t')\n",
    "code_GM_16 = np.loadtxt(\"./BaseGraph_GM/LDPC_GM_BG2_16.txt\", int, delimiter=',')\n",
    "code_GM_3 = np.loadtxt(\"./BaseGraph_GM/LDPC_GM_BG2_3.txt\", int, delimiter=',')\n",
    "code_GM_10 = np.loadtxt(\"./BaseGraph_GM/LDPC_GM_BG2_10.txt\", int, delimiter=',')\n",
    "code_GM_6 = np.loadtxt(\"./BaseGraph_GM/LDPC_GM_BG2_6.txt\", int, delimiter=',')\n",
    "code_PCM = code_PCM0.copy()\n",
    "Ldpc_PCM = [code_PCM0, code_PCM1, code_PCM2, code_PCM1]# four LDPC codes with different code lengths\n",
    "Ldpc_GM = [code_GM_16, code_GM_3, code_GM_10, code_GM_6]\n",
    "Z_array = np.array([16, 3, 10, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b344214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  9, 117, 204, ...,  -1,  -1,  -1],\n",
       "       [167,  -1,  -1, ...,  -1,  -1,  -1],\n",
       "       [ 81, 114,  -1, ...,  -1,  -1,  -1],\n",
       "       ...,\n",
       "       [239,  -1,  -1, ...,   0,  -1,  -1],\n",
       "       [ -1,  -1,   0, ...,  -1,   0,  -1],\n",
       "       [ -1, 129,  -1, ...,  -1,  -1,   0]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_PCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f48f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 17:19:44.320673: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-04-08 17:19:44.320690: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/PIL/ImageFile.py:547\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 547\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m()\n\u001b[1;32m    548\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Visualize base graphs (parity check matrices)\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[43mvisualize_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode_PCM0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBase Graph 2 Set 0 (Parity Check Matrix)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbase_graph_0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m visualize_matrix(code_PCM1, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase Graph 2 Set 1 (Parity Check Matrix)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_graph_1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m visualize_matrix(code_PCM2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase Graph 2 Set 2 (Parity Check Matrix)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_graph_2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[52], line 45\u001b[0m, in \u001b[0;36mvisualize_matrix\u001b[0;34m(matrix, title, filename)\u001b[0m\n\u001b[1;32m     43\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRow Index\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     44\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m---> 45\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./Visualizations/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/matplotlib/pyplot.py:1023\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39msavefig)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavefig\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1022\u001b[0m     fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[0;32m-> 1023\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/matplotlib/figure.py:3378\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3374\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3375\u001b[0m         stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m   3376\u001b[0m             ax\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39m_cm_set(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m-> 3378\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/matplotlib/backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2366\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2368\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2372\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2373\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/matplotlib/backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2228\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2231\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2232\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/matplotlib/backends/backend_agg.py:458\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 458\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/matplotlib/image.py:1689\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1687\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1688\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[0;32m-> 1689\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/PIL/Image.py:2568\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2565\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n\u001b[1;32m   2567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2568\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2569\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   2570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/PIL/PngImagePlugin.py:1431\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1427\u001b[0m     im \u001b[38;5;241m=\u001b[39m _write_multiple_frames(\n\u001b[1;32m   1428\u001b[0m         im, fp, chunk, mode, rawmode, default_image, append_images\n\u001b[1;32m   1429\u001b[0m     )\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im:\n\u001b[0;32m-> 1431\u001b[0m     \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_idat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/PIL/ImageFile.py:551\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    549\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 551\u001b[0m     \u001b[43m_encode_tile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    553\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/PIL/ImageFile.py:570\u001b[0m, in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 570\u001b[0m         errcode, data \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    571\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[1;32m    572\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "# GPU settings\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "# get the base graph and generator matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create directories for visualizations if they don't exist\n",
    "os.makedirs(\"./Visualizations\", exist_ok=True)\n",
    "\n",
    "# Load matrices\n",
    "code_PCM0 = np.loadtxt(\"./BaseGraph/BaseGraph2_Set0.txt\", int, delimiter='\\t')\n",
    "code_PCM1 = np.loadtxt(\"./BaseGraph/BaseGraph2_Set1.txt\", int, delimiter='\\t')\n",
    "code_PCM2 = np.loadtxt(\"./BaseGraph/BaseGraph2_Set2.txt\", int, delimiter='\\t')\n",
    "code_GM_16 = np.loadtxt(\"./BaseGraph_GM/LDPC_GM_BG2_16.txt\", int, delimiter=',')\n",
    "code_GM_3 = np.loadtxt(\"./BaseGraph_GM/LDPC_GM_BG2_3.txt\", int, delimiter=',')\n",
    "code_GM_10 = np.loadtxt(\"./BaseGraph_GM/LDPC_GM_BG2_10.txt\", int, delimiter=',')\n",
    "code_GM_6 = np.loadtxt(\"./BaseGraph_GM/LDPC_GM_BG2_6.txt\", int, delimiter=',')\n",
    "code_PCM = code_PCM0.copy()\n",
    "\n",
    "# Function to visualize a matrix as a heatmap\n",
    "def visualize_matrix(matrix, title, filename):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    # Replace -1 values with a different color for better visualization\n",
    "    display_matrix = matrix.copy()\n",
    "    if -1 in display_matrix:\n",
    "        cmap = plt.cm.viridis\n",
    "        display_matrix[display_matrix == -1] = -0.5\n",
    "        vmin, vmax = -0.5, max(1, display_matrix.max())\n",
    "    else:\n",
    "        cmap = plt.cm.binary\n",
    "        vmin, vmax = 0, 1\n",
    "        \n",
    "    plt.imshow(display_matrix, cmap=cmap, aspect='auto', vmin=vmin, vmax=vmax)\n",
    "    plt.colorbar(label='Value')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Column Index')\n",
    "    plt.ylabel('Row Index')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./Visualizations/{filename}.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "# Visualize base graphs (parity check matrices)\n",
    "visualize_matrix(code_PCM0, \"Base Graph 2 Set 0 (Parity Check Matrix)\", \"base_graph_0\")\n",
    "visualize_matrix(code_PCM1, \"Base Graph 2 Set 1 (Parity Check Matrix)\", \"base_graph_1\")\n",
    "visualize_matrix(code_PCM2, \"Base Graph 2 Set 2 (Parity Check Matrix)\", \"base_graph_2\")\n",
    "\n",
    "# Visualize generator matrices\n",
    "visualize_matrix(code_GM_16, f\"Generator Matrix (Z=16, {code_GM_16.shape})\", \"gen_matrix_16\")\n",
    "visualize_matrix(code_GM_3, f\"Generator Matrix (Z=3, {code_GM_3.shape})\", \"gen_matrix_3\")\n",
    "visualize_matrix(code_GM_10, f\"Generator Matrix (Z=10, {code_GM_10.shape})\", \"gen_matrix_10\")\n",
    "visualize_matrix(code_GM_6, f\"Generator Matrix (Z=6, {code_GM_6.shape})\", \"gen_matrix_6\")\n",
    "\n",
    "# Plot connectivity graph for one of the PCMs to visualize the LDPC structure\n",
    "def plot_tanner_graph(H, max_nodes=50, title=\"Tanner Graph Representation\"):\n",
    "    try:\n",
    "        \n",
    "        # Create a bipartite graph\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        # Limit the size for visualization purposes\n",
    "        m, n = min(H.shape[0], max_nodes), min(H.shape[1], max_nodes)\n",
    "        \n",
    "        # Add variable nodes (columns)\n",
    "        var_nodes = [f\"v{i}\" for i in range(n)]\n",
    "        # Add check nodes (rows)\n",
    "        check_nodes = [f\"c{i}\" for i in range(m)]\n",
    "        \n",
    "        # Add all nodes to the graph\n",
    "        G.add_nodes_from(var_nodes, bipartite=0)\n",
    "        G.add_nodes_from(check_nodes, bipartite=1)\n",
    "        \n",
    "        # Add edges where H[i,j] != 0 and H[i,j] != -1\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                if H[i,j] > 0:  # Only connect if there's a positive value (connection)\n",
    "                    G.add_edge(f\"c{i}\", f\"v{j}\")\n",
    "                    \n",
    "        # Create a layout for visualization\n",
    "        pos = nx.spring_layout(G)\n",
    "        \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        # Draw variable nodes\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=var_nodes, node_color='skyblue', \n",
    "                              node_size=300, label=\"Variable Nodes\")\n",
    "        # Draw check nodes\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=check_nodes, node_color='lightgreen', \n",
    "                              node_size=300, label=\"Check Nodes\")\n",
    "        # Draw edges\n",
    "        nx.draw_networkx_edges(G, pos, width=0.5, alpha=0.5)\n",
    "        # Draw labels\n",
    "        nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"./Visualizations/tanner_graph.png\", dpi=300)\n",
    "        plt.close()\n",
    "    except ImportError:\n",
    "        print(\"NetworkX library not found. Skipping Tanner graph visualization.\")\n",
    "\n",
    "# Try to plot a Tanner graph representation for code_PCM0\n",
    "plot_tanner_graph(code_PCM0, title=\"LDPC Tanner Graph (Base Graph 2 Set 0)\")\n",
    "\n",
    "# Function to visualize training convergence\n",
    "def setup_convergence_plot():\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(\"Neural LDPC Decoder Training Progress\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0cd6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "457a9053",
   "metadata": {},
   "source": [
    "`code_PCM`: loaded from BaseGraph/BaseGraph2_Set0.txt through \n",
    "\n",
    "ShapeLayer: why make code_PCM to have 0 or 1 value after loaded form text file and copy immediately?\n",
    "\n",
    "GitHub.copilot-chat.github.copilot.editor: # LDPC Code Matrix Processing\n",
    "\n",
    "This code is processing Parity Check Matrices (PCMs) for Low-Density Parity-Check (LDPC) codes. Here's why the code is converting values to 0 or 1:\n",
    "\n",
    "The code loads several PCMs from text files, then copies `code_PCM0` to `code_PCM`. After loading these matrices, the code processes `code_PCM` by converting:\n",
    "- Values of `-1` to `0`\n",
    "- All other values to `1`\n",
    "\n",
    "This transformation is performed because:\n",
    "\n",
    "1. **Binary representation**: LDPC codes typically work with binary matrices. However, some representations use `-1` to indicate \"no connection\" between nodes in the Tanner graph.\n",
    "\n",
    "2. **Standard format**: Converting to 0/1 values puts the matrix in a standard binary format that's needed for subsequent operations in LDPC decoding algorithms.\n",
    "\n",
    "3. **Numerical operations**: Having consistent 0/1 values simplifies matrix operations like multiplication that might be used later in the code.\n",
    "\n",
    "The timing is noteworthy - the code first loads all matrices, creates a copy of `code_PCM0`, and then only processes that copy. The original matrices in `Ldpc_PCM` and `Ldpc_GM` arrays remain unchanged, suggesting these unchanged matrices may be used separately in their original form elsewhere in the program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc08e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "486c299a",
   "metadata": {},
   "source": [
    "ShapeLayer: then this code represents hypothetical situation that converting value to binary when input numerical matrix?\n",
    "\n",
    "GitHub Copilot: Yes, this code represents converting a numerical matrix into a binary representation, but it's not just a hypothetical situation. Let me explain why:\n",
    "\n",
    "## Matrix Conversion Process\n",
    "\n",
    "```python\n",
    "# Original matrix loaded from file contains -1 and positive integers\n",
    "code_PCM = code_PCM0.copy()\n",
    "\n",
    "# Converting to binary (0/1) representation\n",
    "for i in range(0, code_PCM.shape[0]):\n",
    "    for j in range(0, code_PCM.shape[1]):\n",
    "        if (code_PCM[i, j] == -1):\n",
    "            code_PCM[i, j] = 0  # No connection\n",
    "        else:\n",
    "            code_PCM[i, j] = 1  # Connection exists\n",
    "```\n",
    "\n",
    "This conversion serves two critical purposes in LDPC decoding:\n",
    "\n",
    "1. **Tanner Graph Structure**\n",
    "   - `-1` → `0`: No edge between nodes\n",
    "   - Any positive value → `1`: Edge exists between nodes\n",
    "   - This binary form directly represents the connectivity in the Tanner graph\n",
    "\n",
    "2. **Neural Network Processing**\n",
    "   - The binary matrix is used to initialize connection matrices:\n",
    "     - `W_odd2even`: Variable node connections\n",
    "     - `W_even2odd`: Check node connections \n",
    "     - `W_output`: Output layer connections\n",
    "\n",
    "The original positive values (before conversion) are preserved in `Ldpc_PCM` for cyclic shift operations using the `Z` lifting factors, while the binary version is used for network structure setup.\n",
    "\n",
    "This is not hypothetical - it's a necessary transformation for implementing a neural LDPC decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657a18fc",
   "metadata": {},
   "source": [
    "ShapeLayer: then there isn't hypothentical situation, why positive value are different each?\n",
    "\n",
    "# Understanding Positive Values in PCM\n",
    "\n",
    "The positive values in the original parity check matrix (PCM) are not hypothetical - they have specific meanings in protograph-based LDPC codes:\n",
    "\n",
    "## PCM Value Meanings\n",
    "\n",
    "1. **Original Values**\n",
    "   - `-1`: No connection between nodes\n",
    "   - Positive integers (e.g., 1, 2, 3...): Cyclic shift values for protograph lifting\n",
    "\n",
    "2. **Binary Conversion**\n",
    "```python\n",
    "# All positive values become 1 for connectivity matrix\n",
    "if (code_PCM[i, j] == -1):\n",
    "    code_PCM[i, j] = 0  # No connection\n",
    "else:\n",
    "    code_PCM[i, j] = 1  # Connection exists\n",
    "```\n",
    "\n",
    "3. **Why Different Positive Values?**\n",
    "   - The original positive values indicate **cyclic shift amounts** used in `Lift_Matrix1` and `Lift_Matrix2`\n",
    "   - Example from the code:\n",
    "```python\n",
    "# Using original values for lifting\n",
    "if (code_PCM1[i, j] != -1):\n",
    "    Lift_num = code_PCM1[i, j] % Z_array[t]  # Get cyclic shift amount\n",
    "    for h in range(0, Z_array[t], 1):\n",
    "        Lift_M1[k * Z_array[t] + h, k * Z_array[t] + (h + Lift_num) % Z_array[t]] = 1\n",
    "```\n",
    "\n",
    "So while the connectivity matrix uses binary values (0/1), the original different positive values are preserved and used for determining cyclic shifts in the lifted (expanded) LDPC code structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd5eb12",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ba013e5",
   "metadata": {},
   "source": [
    "ShapeLayer: then origin code_pcm is \"cyclic shift values\" and overrided code_pcm is boolean that represents i, j is connected?\n",
    "\n",
    "\n",
    "\n",
    "Copilot:\n",
    "# Understanding the Two Uses of PCM Matrix\n",
    "\n",
    "Yes, exactly! The PCM (Parity Check Matrix) serves two different purposes:\n",
    "\n",
    "1. **Original PCM** (before conversion):\n",
    "```python\n",
    "# Original PCM contains cyclic shift values\n",
    "code_PCM0 = np.loadtxt(\"./BaseGraph/BaseGraph2_Set0.txt\", int, delimiter='\\t')\n",
    "# Values:\n",
    "# -1: No connection\n",
    "# Positive integers: Cyclic shift amounts for each connection\n",
    "```\n",
    "\n",
    "2. **Converted PCM** (after binary conversion):\n",
    "```python\n",
    "# Convert to binary connectivity matrix\n",
    "code_PCM = code_PCM0.copy()\n",
    "for i in range(0, code_PCM.shape[0]):\n",
    "    for j in range(0, code_PCM.shape[1]):\n",
    "        if (code_PCM[i, j] == -1):\n",
    "            code_PCM[i, j] = 0  # No connection\n",
    "        else:\n",
    "            code_PCM[i, j] = 1  # Connection exists\n",
    "```\n",
    "\n",
    "## Key Differences\n",
    "- **Original PCM** (`Ldpc_PCM`): Used for cyclic shifts in protograph lifting\n",
    "  - Preserves shift values for `Lift_Matrix1` and `Lift_Matrix2` construction\n",
    "  - Example: `Lift_num = code_PCM1[i, j] % Z_array[t]`\n",
    "\n",
    "- **Converted PCM** (`code_PCM`): Used for neural network connectivity\n",
    "  - Binary representation (0/1) showing node connections\n",
    "  - Used to build connection matrices like `W_odd2even`, `W_even2odd`, `W_output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9ab5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 52\n",
    "m = 42\n",
    "code_n = N\n",
    "code_k = N - m\n",
    "for i in range(0, code_PCM.shape[0]):\n",
    "    for j in range(0, code_PCM.shape[1]):\n",
    "        if (code_PCM[i, j] == -1):\n",
    "            code_PCM[i, j] = 0\n",
    "        else:\n",
    "            code_PCM[i, j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3df30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 1, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_PCM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f7ca4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52b99ca5",
   "metadata": {},
   "source": [
    "ShapeLayer: \"iterations the network\" in the statement \"The code first defines iters_max = 25, which specifies the maximum number of decoding iterations the network will perform. This is a typical value for LDPC decoding algorithms.\" menas neural network?\n",
    "\n",
    "---\n",
    "\n",
    "Copilot:\n",
    "\n",
    "No, in this context \"iterations\" refers to the message-passing decoding iterations of the LDPC decoder, not neural network training iterations. Let me explain:\n",
    "\n",
    "1. LDPC Decoding Iterations (iters_max = 25):\n",
    "    - This represents how many times messages are passed between variable nodes and check nodes in the Tanner graph\n",
    "    - In traditional LDPC decoding, messages are iteratively exchanged until a valid codeword is found or max iterations reached\n",
    "    - 25 iterations is a typical number for LDPC decoders to achieve good error correction\n",
    "2. Neural Network Training (different concept):\n",
    "    - The actual neural network training is controlled by num_of_batch = 50000\n",
    "    - Training happens in the last section with the loop for iter in range(0, iters_max, 1):\n",
    "    - Each decoder iteration is implemented as a neural network layer, but iters_max controls decoder depth, not training epochs\n",
    "\n",
    "    \n",
    "So while this is a neural implementation of an LDPC decoder, the iters_max parameter represents the number of decoder iterations, which is being modeled using 25 sequential neural network layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcfdd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network hyper-parameters\n",
    "iters_max = 25     # number of iterations\n",
    "sum_edge_c = np.sum(code_PCM, axis=1)\n",
    "sum_edge_v = np.sum(code_PCM, axis=0)\n",
    "sum_edge = np.sum(sum_edge_v)\n",
    "neurons_per_even_layer = neurons_per_odd_layer = np.sum(sum_edge_v)\n",
    "input_output_layer_size = N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b7abea",
   "metadata": {},
   "source": [
    "ShapeLayer: what is the AWGN\n",
    "\n",
    "GitHub Copilot: AWGN stands for Additive White Gaussian Noise, which is a basic noise model used in information theory to mimic the effects of random processes that occur in nature. In this code, AWGN is used to simulate channel noise in the communication system. Let's break down how it's implemented:\n",
    "\n",
    "1. First, the code calculates noise parameters:\n",
    "```python\n",
    "code_rate = 1.0 * (N - m) / (N-2)\n",
    "SNR_Matrix = np.array([[9.0,6.05,4.1,...],  # Signal-to-Noise Ratio (SNR) values\n",
    "                       [9.1,6.2,4.6,...],\n",
    "                       [9,6.05,4.1,...],\n",
    "                       [9.0,6.1,4.25,...]])\n",
    "SNR_lin = 10.0 ** (SNR_Matrix / 10.0)  # Convert SNR from dB to linear scale\n",
    "SNR_sigma = np.sqrt(1.0 / (2.0 * SNR_lin * code_rate))  # Calculate noise standard deviation\n",
    "```\n",
    "\n",
    "2. The AWGN is applied in the `create_mix_epoch` function:\n",
    "```python\n",
    "# Add AWGN to the signal\n",
    "X_p_i = noiseRandom.normal(0.0, 1.0, Y_i.shape) * sf_i + (-1) ** (1 - Y_i)\n",
    "# where:\n",
    "# - noiseRandom.normal(0.0, 1.0, ...) generates Gaussian noise with mean 0 and variance 1\n",
    "# - sf_i is the scaling factor (noise standard deviation)\n",
    "# - (-1) ** (1 - Y_i) converts binary 0/1 to BPSK symbols (-1/+1)\n",
    "```\n",
    "\n",
    "Key characteristics of AWGN:\n",
    "- Additive: The noise is added to the signal\n",
    "- White: The noise has uniform power across the frequency spectrum\n",
    "- Gaussian: The noise follows a normal (Gaussian) distribution\n",
    "- The noise samples are statistically independent\n",
    "\n",
    "This noise model is commonly used in communication systems to test the robustness of error correction codes like LDPC codes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081486a2",
   "metadata": {},
   "source": [
    "ShapeLayer: what is the `SNR_Matrix`? why this literal value are setted like that\n",
    "\n",
    "GitHub Copilot: # SNR_Matrix Explained: Curriculum Learning for Neural LDPC Decoding\n",
    "\n",
    "The `SNR_Matrix` is a 4×25 array of Signal-to-Noise Ratio (SNR) values in decibels (dB) that serves as a curriculum learning schedule for training the neural LDPC decoder across different configurations.\n",
    "\n",
    "## Structure and Function\n",
    "\n",
    "```python\n",
    "SNR_Matrix = np.array([\n",
    "    [9.0, 6.05, 4.1, ..., 0.7],  # For Z=16 configuration\n",
    "    [9.1, 6.2, 4.6, ..., 2.25],  # For Z=3 configuration\n",
    "    [9.0, 6.05, 4.1, ..., 1.0],  # For Z=10 configuration\n",
    "    [9.0, 6.1, 4.25, ..., 1.4]   # For Z=6 configuration\n",
    "])\n",
    "```\n",
    "\n",
    "- **Rows (4)**: Each row corresponds to one of the four LDPC code configurations (Z=16, Z=3, Z=10, Z=6)\n",
    "- **Columns (25)**: Each column corresponds to one of the 25 decoder iterations (`iters_max=25`)\n",
    "- **Values**: Signal-to-Noise Ratio in dB, used to compute `SNR_sigma` (noise standard deviation)\n",
    "\n",
    "## Why These Specific Values?\n",
    "\n",
    "These values implement a curriculum learning strategy:\n",
    "\n",
    "1. **Gradually Decreasing SNR Values**: \n",
    "   - Start with high SNR (around 9dB) → easier decoding tasks with minimal noise\n",
    "   - End with low SNR (0.7-2.25dB) → challenging decoding tasks with significant noise\n",
    "   \n",
    "2. **Code-Specific Considerations**:\n",
    "   - Different rows have different profiles because each LDPC configuration has unique performance characteristics\n",
    "   - Z=3 configuration (row 2) has higher SNR values overall, suggesting it requires cleaner signals\n",
    "   - Z=16 configuration (row 1) reaches the lowest SNR (0.7dB), suggesting better noise tolerance\n",
    "\n",
    "3. **Plateauing Values**:\n",
    "   - The values at the end of each row stabilize (e.g., multiple 0.7s in first row)\n",
    "   - This represents reaching a minimum effective SNR for each configuration\n",
    "\n",
    "During training, the appropriate noise level is selected based on the current iteration and LDPC configuration:\n",
    "```python\n",
    "SNR_set = np.array([SNR_sigma[Z_type, iter]])\n",
    "```\n",
    "\n",
    "This approach allows the neural network to learn decoding strategies gradually, starting with simpler scenarios before tackling more challenging ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the AWGN #\n",
    "code_rate = 1.0 * (N - m) / (N-2)\n",
    "# train SNR\n",
    "SNR_Matrix = np.array([[9.0,6.05,4.1,2.95,2.25,1.8,1.55,1.3,1.15,1.05,0.94,0.85,0.83,0.81,0.8,0.8,0.8,0.75,0.75,0.7,0.7,0.7,0.7,0.7,0.7],\n",
    "                       [9.1,6.2,4.6,3.7,3.2,3.0,2.8,2.7,2.6,2.55,2.5,2.45,2.4,2.4,2.4,2.35,2.35,2.3,2.3,2.3,2.25,2.25,2.25,2.25,2.25],\n",
    "                       [9,6.05,4.1,3,2.4,2,1.7,1.5,1.4,1.4,1.3,1.3,1.2,1.2,1.2,1.2,1.1,1.1,1.1,1.1,1.1,1.1,1.1,1,1],\n",
    "                       [9.0,6.1,4.25,3.2,2.6,2.25,2,1.9,1.8,1.7,1.7,1.65,1.6,1.6,1.55,1.55,1.5,1.5,1.5,1.45,1.45,1.4,1.4,1.4,1.4]])\n",
    "    # Linear SNR\n",
    "SNR_lin = 10.0 ** (SNR_Matrix / 10.0)\n",
    "    # Noise Standard Deviation\n",
    "SNR_sigma = np.sqrt(1.0 / (2.0 * SNR_lin * code_rate))\n",
    "# ramdom seed\n",
    "word_seed = 2042\n",
    "noise_seed = 1074\n",
    "wordRandom = np.random.RandomState(word_seed)  # word seed\n",
    "noiseRandom = np.random.RandomState(noise_seed)  # noise seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train settings\n",
    "learning_rate = 0.001\n",
    "train_on_zero_word = True\n",
    "numOfWordSim_train = 50\n",
    "batch_size = numOfWordSim_train\n",
    "num_of_batch = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7cf275",
   "metadata": {},
   "source": [
    "ShapeLayer: what is the `create_mix_epoch`?\n",
    "\n",
    "GitHub Copilot: # `create_mix_epoch` Function Explanation\n",
    "\n",
    "The `create_mix_epoch` function is a data generation utility that creates training batches for the neural LDPC decoder. It simulates the entire communication process from encoding to channel transmission.\n",
    "\n",
    "## Function Purpose\n",
    "\n",
    "```python\n",
    "def create_mix_epoch(scaling_factor, wordRandom, noiseRandom, numOfWordSim, \n",
    "                     code_n, code_k, Z, code_GM, is_zeros_word):\n",
    "```\n",
    "\n",
    "This function generates pairs of:\n",
    "- **Input data (X)**: Noisy channel observations (as log-likelihood ratios)\n",
    "- **Target labels (Y)**: Original codeword bits\n",
    "\n",
    "## Step-by-Step Process\n",
    "\n",
    "1. **Information Bit Generation**:\n",
    "   ```python\n",
    "   if is_zeros_word:\n",
    "       infoWord_i = 0 * wordRandom.randint(0, 2, size=(numOfWordSim, code_k * Z))\n",
    "   else:\n",
    "       infoWord_i = wordRandom.randint(0, 2, size=(numOfWordSim, code_k * Z))\n",
    "   ```\n",
    "   - Either generates random information bits or all-zeros words\n",
    "   - The `train_on_zero_word = True` parameter is set globally to use all-zeros\n",
    "\n",
    "2. **LDPC Encoding**:\n",
    "   ```python\n",
    "   Y_i = np.dot(infoWord_i, code_GM) % 2\n",
    "   ```\n",
    "   - Multiplies information bits with generator matrix\n",
    "   - Modulo-2 operation produces binary codewords\n",
    "\n",
    "3. **Channel Transmission Simulation**:\n",
    "   ```python\n",
    "   X_p_i = noiseRandom.normal(0.0, 1.0, Y_i.shape) * sf_i + (-1) ** (1 - Y_i)\n",
    "   ```\n",
    "   - Converts bits to BPSK symbols (0→-1, 1→1)\n",
    "   - Adds AWGN (Additive White Gaussian Noise) scaled by `sf_i`\n",
    "   - `sf_i` is derived from the SNR value for the current iteration\n",
    "\n",
    "4. **LLR Calculation**:\n",
    "   ```python\n",
    "   x_llr_i = 2 * X_p_i / ((sf_i) ** 2)\n",
    "   ```\n",
    "   - Converts received symbols to Log-Likelihood Ratios\n",
    "   - These are soft-decision values used by the decoder\n",
    "\n",
    "5. **Data Organization**:\n",
    "   ```python\n",
    "   X = np.vstack((X, x_llr_i))\n",
    "   Y = np.vstack((Y, Y_i))\n",
    "   X = X[1:]\n",
    "   Y = Y[1:]\n",
    "   X = np.reshape(X, [batch_size, code_n, Z])\n",
    "   ```\n",
    "   - Accumulates data for the full batch\n",
    "   - Reshapes X to match the network's expected input format\n",
    "\n",
    "## Usage in Training\n",
    "\n",
    "This function is called during the training loop for each of the four LDPC configurations:\n",
    "\n",
    "```python\n",
    "SNR_set = np.array([SNR_sigma[Z_type, iter]])\n",
    "training_received_data, training_coded_bits = create_mix_epoch(\n",
    "    SNR_set, wordRandom, noiseRandom, numOfWordSim_train,\n",
    "    code_n, code_k, Z, Ldpc_GM[Z_type], train_on_zero_word)\n",
    "```\n",
    "\n",
    "The function implements a curriculum learning strategy where noise levels gradually increase (SNR decreases) as training progresses through the iterations, making the learning task progressively more challenging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b00eb5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28019074",
   "metadata": {},
   "source": [
    "ShapeLayer: what does that mean \"# pay attention to this 1->1 o->-1\"\n",
    "\n",
    "GitHub Copilot: # BPSK Modulation Explained: `1->1 0->-1`\n",
    "\n",
    "This comment refers to the Binary Phase Shift Keying (BPSK) modulation happening in this line:\n",
    "\n",
    "```python\n",
    "X_p_i = noiseRandom.normal(0.0, 1.0, Y_i.shape) * sf_i + (-1) ** (1 - Y_i)\n",
    "```\n",
    "\n",
    "## What It Means\n",
    "\n",
    "The comment `# pay attention to this 1->1 0->-1` is explaining the mathematical mapping occurring with the expression `(-1) ** (1 - Y_i)`:\n",
    "\n",
    "- When `Y_i` = 1 (binary bit '1'):\n",
    "  - `1 - Y_i` = 0\n",
    "  - `(-1) ** 0` = 1\n",
    "  - So binary '1' → transmitted symbol '+1'\n",
    "\n",
    "- When `Y_i` = 0 (binary bit '0'):\n",
    "  - `1 - Y_i` = 1\n",
    "  - `(-1) ** 1` = -1\n",
    "  - So binary '0' → transmitted symbol '-1'\n",
    "\n",
    "## Why It's Important\n",
    "\n",
    "This transformation is crucial because:\n",
    "\n",
    "1. **BPSK Modulation**: This is the standard method for converting binary data to antipodal signals for transmission\n",
    "\n",
    "2. **Signal Energy**: The ±1 representation ensures equal energy per bit, which is optimal for noise resistance\n",
    "\n",
    "3. **AWGN Channel Simulation**: The full line simulates transmission over a noisy channel:\n",
    "   ```\n",
    "   BPSK symbol + Gaussian noise = Received symbol\n",
    "      ±1      + random noise   = X_p_i\n",
    "   ```\n",
    "\n",
    "4. **LLR Calculation**: This representation makes it easier to calculate Log-Likelihood Ratios (LLRs) in the following line, which are the soft inputs required by the neural LDPC decoder\n",
    "\n",
    "In summary, this comment highlights a key part of the digital communication system being simulated - the conversion from binary data to BPSK symbols before transmission through the noisy channel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1303a8f0",
   "metadata": {},
   "source": [
    "## 모델 학습 데이터 생성 <sup><code>create_mix_epoch</code></sup>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\n",
    "\\text{info}_i &= \\begin{cases}\n",
    "  \\text{random}(\\text{WordSim}, code_k \\cdot Z) & \\text{if } \\text{is\\_zeros\\_word} = \\text{False} \\\\\n",
    "  0_{(\\text{WordSim}, code_k \\cdot Z)} & \\text{if } \\text{is\\_zeros\\_word} = \\text{True}\n",
    "\\end{cases} \\\\[1em]\n",
    "\n",
    "Y_i &= \\text{info}_i \\cdot G \\\\[0.5em]\n",
    "X_{p_i} &= \\text{Random} \\cdot \\text{Scaler}_i + (-1)^{1-Y_i} \\\\[0.5em]\n",
    "X_{\\text{llr}_i} &= 2X_{p_i}/\\text{Scaler}_i^2 \\\\[0.5em]\n",
    "\n",
    "X &= \\begin{bmatrix}\n",
    "X_{\\text{llr}_1} \\\\\n",
    "X_{\\text{llr}_2} \\\\\n",
    "\\vdots \\\\\n",
    "X_{\\text{llr}_n}\n",
    "\\end{bmatrix} \\\\[0.5em]\n",
    "\n",
    "Y &= \\begin{bmatrix}\n",
    "  Y_1 \\\\\n",
    "  Y_2 \\\\\n",
    "  \\vdots \\\\\n",
    "  Y_n\n",
    "\\end{bmatrix} \\\\[0.5em]\n",
    "\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$\\therefore$ $X$ = 노이즈를 거친 코드워드의 LLR; $y$ = 원래 코드워드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c8f72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used at Training\n",
    "\n",
    "# In the context of this neural LDPC decoding code, the term \"mix\" \n",
    "# in the create_mix_epoch function refers to the mixing of multiple \n",
    "# elements to create comprehensive training batches. The function \n",
    "# creates mixed training data in several ways:\n",
    "\n",
    "#get train samples\n",
    "def create_mix_epoch(scaling_factor, wordRandom, noiseRandom, numOfWordSim, code_n, code_k, Z, code_GM, is_zeros_word):\n",
    "    X = np.zeros([1, code_n * Z], dtype=np.float32)\n",
    "    Y = np.zeros([1, code_n * Z], dtype=np.int64)\n",
    "\n",
    "    # build set for epoch\n",
    "    for sf_i in scaling_factor:\n",
    "        if is_zeros_word:\n",
    "            infoWord_i = 0 * wordRandom.randint(0, 2, size=(numOfWordSim, code_k * Z))\n",
    "        else:\n",
    "            infoWord_i = wordRandom.randint(0, 2, size=(numOfWordSim, code_k * Z))\n",
    "\n",
    "        Y_i = np.dot(infoWord_i, code_GM) % 2\n",
    "        # Generate data with specific noise level\n",
    "        X_p_i = noiseRandom.normal(0.0, 1.0, Y_i.shape) * sf_i + (-1) ** (1 - Y_i)  # pay attention to this 1->1 0->-1\n",
    "        x_llr_i = 2 * X_p_i / ((sf_i) ** 2)  # defined as p1/p0\n",
    "        X = np.vstack((X, x_llr_i))\n",
    "        Y = np.vstack((Y, Y_i))\n",
    "    X = X[1:]\n",
    "    Y = Y[1:]\n",
    "    X = np.reshape(X, [batch_size, code_n, Z])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd7894f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ber and fer\n",
    "def calc_ber_fer(snr_db, Y_test_pred, Y_test, numOfWordSim):\n",
    "    ber_test = np.zeros(snr_db.shape[0])\n",
    "    fer_test = np.zeros(snr_db.shape[0])\n",
    "    for i in range(0, snr_db.shape[0]):\n",
    "        Y_test_pred_i = Y_test_pred[i * numOfWordSim:(i + 1) * numOfWordSim, :]\n",
    "        Y_test_i = Y_test[i * numOfWordSim:(i + 1) * numOfWordSim, :]\n",
    "        ber_test[i] = np.abs(((Y_test_pred_i > 0) - Y_test_i)).sum() / (Y_test_i.shape[0] * Y_test_i.shape[1])\n",
    "        fer_test[i] = (np.abs(((Y_test_pred_i > 0) - Y_test_i)).sum(axis=1) > 0).sum() * 1.0 / Y_test_i.shape[0]\n",
    "    return ber_test, fer_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47259105",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################     init the connecting matrix between network layers   #################################\n",
    "Lift_Matrix1 = []\n",
    "Lift_Matrix2 = []\n",
    "W_odd2even = np.zeros((sum_edge, sum_edge), dtype=np.float32)\n",
    "W_skipconn2even = np.zeros((N, sum_edge), dtype=np.float32)\n",
    "W_even2odd = np.zeros((sum_edge, sum_edge), dtype=np.float32)\n",
    "W_output = np.zeros((sum_edge, N), dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49cc2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init lifting matrix for cyclic shift\n",
    "for t in range(0, 4, 1):\n",
    "    Lift_M1 = np.zeros((neurons_per_odd_layer * Z_array[t], neurons_per_odd_layer * Z_array[t]), np.float32)\n",
    "    Lift_M2 = np.zeros((neurons_per_odd_layer * Z_array[t], neurons_per_odd_layer * Z_array[t]), np.float32)\n",
    "    code_PCM1 = Ldpc_PCM[t]\n",
    "    k = 0\n",
    "    for j in range(0, code_PCM1.shape[1]):\n",
    "        for i in range(0, code_PCM1.shape[0]):\n",
    "            if (code_PCM1[i, j] != -1):\n",
    "                Lift_num = code_PCM1[i, j] % Z_array[t]\n",
    "                for h in range(0, Z_array[t], 1):\n",
    "                    Lift_M1[k * Z_array[t] + h, k * Z_array[t] + (h + Lift_num) % Z_array[t]] = 1\n",
    "                k = k + 1\n",
    "    k = 0\n",
    "    for i in range(0, code_PCM1.shape[0]):\n",
    "        for j in range(0, code_PCM1.shape[1]):\n",
    "            if (code_PCM1[i, j] != -1):\n",
    "                Lift_num = code_PCM1[i, j] % Z_array[t]\n",
    "                for h in range(0, Z_array[t], 1):\n",
    "                    Lift_M2[k * Z_array[t] + h, k * Z_array[t] + (h + Lift_num) % Z_array[t]] = 1\n",
    "                k = k + 1\n",
    "    Lift_Matrix1.append(Lift_M1)\n",
    "    Lift_Matrix2.append(Lift_M2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0921c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init W_odd2even  variable node updating\n",
    "k = 0\n",
    "vec_tmp = np.zeros((sum_edge), dtype=np.float32)  # even layer index read with column\n",
    "for j in range(0, code_PCM.shape[1], 1):  # run over the columns\n",
    "    for i in range(0, code_PCM.shape[0], 1):  # break after the first one\n",
    "        if (code_PCM[i, j] == 1):  # finding the first one is ok\n",
    "            num_of_conn = int(np.sum(code_PCM[:, j]))  # get the number of connection of the variable node\n",
    "            idx = np.argwhere(code_PCM[:, j] == 1)  # get the indexes\n",
    "            for l in range(0, num_of_conn, 1):  # adding num_of_conn columns to W\n",
    "                vec_tmp = np.zeros((sum_edge), dtype=np.float32)\n",
    "                for r in range(0, code_PCM.shape[0], 1):  # adding one to the right place\n",
    "                    if (code_PCM[r, j] == 1 and idx[l][0] != r):\n",
    "                        idx_row = np.cumsum(code_PCM[r, 0:j + 1])[-1] - 1\n",
    "                        odd_layer_node_count = 0\n",
    "                        if r > 0:\n",
    "                            odd_layer_node_count = np.cumsum(sum_edge_c[0:r])[-1]\n",
    "                        vec_tmp[idx_row + odd_layer_node_count] = 1  # offset index adding\n",
    "                W_odd2even[:, k] = vec_tmp.transpose()\n",
    "                k += 1\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a147620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init W_even2odd  parity check node updating\n",
    "k = 0\n",
    "for j in range(0, code_PCM.shape[1], 1):\n",
    "    for i in range(0, code_PCM.shape[0], 1):\n",
    "        if (code_PCM[i, j] == 1):\n",
    "            idx_row = np.cumsum(code_PCM[i, 0:j + 1])[-1] - 1\n",
    "            idx_col = np.cumsum(code_PCM[0: i + 1, j])[-1] - 1\n",
    "            odd_layer_node_count_1 = 0\n",
    "            odd_layer_node_count_2 = np.cumsum(sum_edge_c[0:i + 1])[-1]\n",
    "            if i > 0:\n",
    "                odd_layer_node_count_1 = np.cumsum(sum_edge_c[0:i])[-1]\n",
    "            W_even2odd[k, odd_layer_node_count_1:odd_layer_node_count_2] = 1.0\n",
    "            W_even2odd[k, odd_layer_node_count_1 + idx_row] = 0.0\n",
    "            k += 1  # k is counted in column direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799bc6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init W_output odd to output\n",
    "k = 0\n",
    "for j in range(0, code_PCM.shape[1], 1):\n",
    "    for i in range(0, code_PCM.shape[0], 1):\n",
    "        if (code_PCM[i, j] == 1):\n",
    "            idx_row = np.cumsum(code_PCM[i, 0:j + 1])[-1] - 1\n",
    "            idx_col = np.cumsum(code_PCM[0: i + 1, j])[-1] - 1\n",
    "            odd_layer_node_count = 0\n",
    "            if i > 0:\n",
    "                odd_layer_node_count = np.cumsum(sum_edge_c[0:i])[-1]\n",
    "            W_output[odd_layer_node_count + idx_row, k] = 1.0\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ec906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init W_skipconn2even  channel input\n",
    "k = 0\n",
    "for j in range(0, code_PCM.shape[1], 1):\n",
    "    for i in range(0, code_PCM.shape[0], 1):\n",
    "        if (code_PCM[i, j] == 1):\n",
    "            W_skipconn2even[j, k] = 1.0\n",
    "            k += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbbb3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################  bulid four neural networks(Z = 16,3, 10, 6) ############################\n",
    "net_dict = {}\n",
    "# init the learnable network parameters\n",
    "Weights_Var = 0.5 * np.ones(sum_edge, dtype=np.float32)\n",
    "Biases_Var = np.zeros(sum_edge, dtype=np.float32)\n",
    "for i in range(0, iters_max, 1):\n",
    "    net_dict[\"Weights_Var{0}\".format(i)] = tf.Variable(Weights_Var.copy(), name=\"Weights_Var\".format(i))\n",
    "    net_dict[\"Biases_Var{0}\".format(i)] = tf.Variable(Biases_Var.copy(), name=\"Biases_Var\".format(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9593e810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    }
   ],
   "source": [
    "# the decoding neural network of Z=16\n",
    "Z = 16\n",
    "xa = tf.placeholder(tf.float32, shape=[batch_size, N, Z], name='xa')\n",
    "ya = tf.placeholder(tf.float32, shape=[batch_size, N * Z], name='ya')\n",
    "xa_input = tf.transpose(xa, [0, 2, 1])\n",
    "net_dict[\"LLRa{0}\".format(0)] = tf.zeros((batch_size, Z, sum_edge), dtype=tf.float32)\n",
    "for i in range(0, iters_max, 1):\n",
    "    #variable node update\n",
    "    x0 = tf.matmul(xa_input, W_skipconn2even)\n",
    "    x1 = tf.matmul(net_dict[\"LLRa{0}\".format(i)], W_odd2even)\n",
    "    x2 = tf.add(x0, x1)\n",
    "    x2 = tf.transpose(x2, [0, 2, 1])\n",
    "    x2 = tf.reshape(x2, [batch_size, neurons_per_odd_layer * Z])\n",
    "    x2 = tf.matmul(x2, Lift_Matrix1[0].transpose())\n",
    "    x2 = tf.reshape(x2, [batch_size, neurons_per_odd_layer, Z])\n",
    "    x2 = tf.transpose(x2, [0, 2, 1])\n",
    "    x_tile = tf.tile(x2, multiples=[1, 1, neurons_per_odd_layer])\n",
    "    W_input_reshape = tf.reshape(W_even2odd.transpose(), [-1])\n",
    "    #check node update\n",
    "    x_tile_mul = tf.multiply(x_tile, W_input_reshape)\n",
    "    x2_1 = tf.reshape(x_tile_mul, [batch_size, Z, neurons_per_odd_layer, neurons_per_odd_layer])\n",
    "    x2_abs = tf.add(tf.abs(x2_1), 10000 * (1 - tf.to_float(tf.abs(x2_1) > 0)))\n",
    "    x3 = tf.reduce_min(x2_abs, axis=3)\n",
    "    x2_2 = -x2_1\n",
    "    x4 = tf.add(tf.zeros((batch_size, Z, neurons_per_odd_layer, neurons_per_odd_layer)), 1 - 2 * tf.to_float(x2_2 < 0))\n",
    "    x4_prod = -tf.reduce_prod(x4, axis=3)\n",
    "    x_output_0 = tf.multiply(x3, tf.sign(x4_prod))\n",
    "    x_output_0 = tf.transpose(x_output_0, [0, 2, 1])\n",
    "    x_output_0 = tf.reshape(x_output_0, [batch_size, Z * neurons_per_odd_layer])\n",
    "    x_output_0 = tf.matmul(x_output_0, Lift_Matrix2[0])\n",
    "    x_output_0 = tf.reshape(x_output_0, [batch_size, neurons_per_odd_layer, Z])\n",
    "    x_output_0 = tf.transpose(x_output_0, [0, 2, 1])\n",
    "    # add learnable parameters\n",
    "    x_output_1 = tf.add(tf.multiply(tf.abs(x_output_0),net_dict[\"Weights_Var{0}\".format(i)]), net_dict[\"Biases_Var{0}\".format(i)])\n",
    "    x_output_1 = tf.multiply(x_output_1, tf.to_float(x_output_1 > 0))\n",
    "    net_dict[\"LLRa{0}\".format(i+1)] = tf.multiply(x_output_1, tf.sign(x_output_0)) # update the LLR\n",
    "    # output\n",
    "    y_output_2 = tf.matmul(net_dict[\"LLRa{0}\".format(i+1)], W_output)\n",
    "    y_output_3 = tf.transpose(y_output_2, [0, 2, 1])\n",
    "    y_output_4 = tf.add(xa, y_output_3)\n",
    "    net_dict[\"ya_output{0}\".format(i)] = tf.reshape(y_output_4, [batch_size, N * Z], name='ya_output'.format(i))\n",
    "    # calculate loss\n",
    "    net_dict[\"lossa{0}\".format(i)] = 1.0 * tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=ya,\n",
    "                                                            logits=net_dict[\"ya_output{0}\".format(i)]), name='lossa'.format(i))\n",
    "    # AdamOptimizer\n",
    "    net_dict[\"train_stepa{0}\".format(i)] = tf.train.AdamOptimizer(learning_rate=\n",
    "                                                                learning_rate).minimize(net_dict[\"lossa{0}\".format(i)],\n",
    "                                var_list = [net_dict[\"Weights_Var{0}\".format(i)], net_dict[\"Biases_Var{0}\".format(i)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf068ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the decoding neural network of Z=3\n",
    "Z = 3\n",
    "xb = tf.placeholder(tf.float32, shape=[batch_size, N, Z], name='xb')\n",
    "yb = tf.placeholder(tf.float32, shape=[batch_size, N * Z], name='yb')\n",
    "xb_input = tf.transpose(xb, [0, 2, 1])\n",
    "net_dict[\"LLRb{0}\".format(0)] = tf.zeros((batch_size, Z, sum_edge), dtype=tf.float32)\n",
    "for i in range(0, iters_max, 1):\n",
    "    #variable node update\n",
    "    x0 = tf.matmul(xb_input, W_skipconn2even)\n",
    "    x1 = tf.matmul(net_dict[\"LLRb{0}\".format(i)], W_odd2even)\n",
    "    x2 = tf.add(x0, x1)\n",
    "    x2 = tf.transpose(x2, [0, 2, 1])\n",
    "    x2 = tf.reshape(x2, [batch_size, neurons_per_odd_layer * Z])\n",
    "    x2 = tf.matmul(x2, Lift_Matrix1[1].transpose())\n",
    "    x2 = tf.reshape(x2, [batch_size, neurons_per_odd_layer, Z])\n",
    "    x2 = tf.transpose(x2, [0, 2, 1])\n",
    "    x_tile = tf.tile(x2, multiples=[1, 1, neurons_per_odd_layer])\n",
    "    W_input_reshape = tf.reshape(W_even2odd.transpose(), [-1])\n",
    "    # check node update\n",
    "    x_tile_mul = tf.multiply(x_tile, W_input_reshape)\n",
    "    x2_1 = tf.reshape(x_tile_mul, [batch_size, Z, neurons_per_odd_layer, neurons_per_odd_layer])\n",
    "    x2_abs = tf.add(tf.abs(x2_1), 100 * (1 - tf.to_float(tf.abs(x2_1) > 0)))\n",
    "    x3 = tf.reduce_min(x2_abs, axis=3)\n",
    "    x2_2 = -x2_1\n",
    "    x4 = tf.add(tf.zeros((batch_size, Z, neurons_per_odd_layer, neurons_per_odd_layer)), 1 - 2 * tf.to_float(x2_2 < 0))\n",
    "    x4_prod = -tf.reduce_prod(x4, axis=3)\n",
    "    x_output_0 = tf.multiply(x3, tf.sign(x4_prod))\n",
    "    x_output_0 = tf.transpose(x_output_0, [0, 2, 1])\n",
    "    x_output_0 = tf.reshape(x_output_0, [batch_size, Z * neurons_per_odd_layer])\n",
    "    x_output_0 = tf.matmul(x_output_0, Lift_Matrix2[1])\n",
    "    x_output_0 = tf.reshape(x_output_0, [batch_size, neurons_per_odd_layer, Z])\n",
    "    x_output_0 = tf.transpose(x_output_0, [0, 2, 1])\n",
    "    # add learnable parameters\n",
    "    x_output_1 = tf.add(tf.multiply(tf.abs(x_output_0), net_dict[\"Weights_Var{0}\".format(i)]), net_dict[\"Biases_Var{0}\".format(i)])\n",
    "    x_output_1 = tf.multiply(x_output_1, tf.to_float(x_output_1 > 0))\n",
    "    net_dict[\"LLRb{0}\".format(i+1)] = tf.multiply(x_output_1, tf.sign(x_output_0))\n",
    "    # output\n",
    "    y_output_2 = tf.matmul(net_dict[\"LLRb{0}\".format(i+1)], W_output)\n",
    "    y_output_3 = tf.transpose(y_output_2, [0, 2, 1])\n",
    "    y_output_4 = tf.add(xb, y_output_3)\n",
    "    net_dict[\"yb_output{0}\".format(i)] = tf.reshape(y_output_4, [batch_size, N * Z], name='yb_output'.format(i))\n",
    "    # calculate loss\n",
    "    net_dict[\"lossb{0}\".format(i)] = 1.0 * tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=yb,\n",
    "                                                            logits=net_dict[\"yb_output{0}\".format(i)]), name='lossb'.format(i))\n",
    "    # AdamOptimizer\n",
    "    net_dict[\"train_stepb{0}\".format(i)] = tf.train.AdamOptimizer(learning_rate=\n",
    "                                                                learning_rate).minimize(net_dict[\"lossb{0}\".format(i)],\n",
    "                                var_list = [net_dict[\"Weights_Var{0}\".format(i)], net_dict[\"Biases_Var{0}\".format(i)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd515cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the decoding neural network of Z=10\n",
    "Z = 10\n",
    "xc = tf.placeholder(tf.float32, shape=[batch_size, N, Z], name='xc')\n",
    "yc = tf.placeholder(tf.float32, shape=[batch_size, N * Z], name='yc')\n",
    "xc_input = tf.transpose(xc, [0, 2, 1])\n",
    "net_dict[\"LLRc{0}\".format(0)] = tf.zeros((batch_size, Z, sum_edge), dtype=tf.float32)\n",
    "for i in range(0, iters_max, 1):\n",
    "    # variable node update\n",
    "    x0 = tf.matmul(xc_input, W_skipconn2even)\n",
    "    x1 = tf.matmul(net_dict[\"LLRc{0}\".format(i)], W_odd2even)\n",
    "    x2 = tf.add(x0, x1)\n",
    "    x2 = tf.transpose(x2, [0, 2, 1])\n",
    "    x2 = tf.reshape(x2, [batch_size, neurons_per_odd_layer * Z])\n",
    "    x2 = tf.matmul(x2, Lift_Matrix1[2].transpose())\n",
    "    x2 = tf.reshape(x2, [batch_size, neurons_per_odd_layer, Z])\n",
    "    x2 = tf.transpose(x2, [0, 2, 1])\n",
    "    x_tile = tf.tile(x2, multiples=[1, 1, neurons_per_odd_layer])\n",
    "    W_input_reshape = tf.reshape(W_even2odd.transpose(), [-1])\n",
    "    # check node update\n",
    "    x_tile_mul = tf.multiply(x_tile, W_input_reshape)\n",
    "    x2_1 = tf.reshape(x_tile_mul, [batch_size, Z, neurons_per_odd_layer, neurons_per_odd_layer])\n",
    "    x2_abs = tf.add(tf.abs(x2_1), 100 * (1 - tf.to_float(tf.abs(x2_1) > 0)))\n",
    "    x3 = tf.reduce_min(x2_abs, axis=3)\n",
    "    x2_2 = -x2_1\n",
    "    x4 = tf.add(tf.zeros((batch_size, Z, neurons_per_odd_layer, neurons_per_odd_layer)), 1 - 2 * tf.to_float(x2_2 < 0))\n",
    "    x4_prod = -tf.reduce_prod(x4, axis=3)\n",
    "    x_output_0 = tf.multiply(x3, tf.sign(x4_prod))\n",
    "    x_output_0 = tf.transpose(x_output_0, [0, 2, 1])\n",
    "    x_output_0 = tf.reshape(x_output_0, [batch_size, Z * neurons_per_odd_layer])\n",
    "    x_output_0 = tf.matmul(x_output_0, Lift_Matrix2[2])\n",
    "    x_output_0 = tf.reshape(x_output_0, [batch_size, neurons_per_odd_layer, Z])\n",
    "    x_output_0 = tf.transpose(x_output_0, [0, 2, 1])\n",
    "    # add learnable parameters\n",
    "    x_output_1 = tf.add(tf.multiply(tf.abs(x_output_0),net_dict[\"Weights_Var{0}\".format(i)]), net_dict[\"Biases_Var{0}\".format(i)])\n",
    "    x_output_1 = tf.multiply(x_output_1, tf.to_float(x_output_1 > 0))\n",
    "    net_dict[\"LLRc{0}\".format(i+1)] = tf.multiply(x_output_1, tf.sign(x_output_0))\n",
    "    # output\n",
    "    y_output_2 = tf.matmul(net_dict[\"LLRc{0}\".format(i+1)], W_output)\n",
    "    y_output_3 = tf.transpose(y_output_2, [0, 2, 1])\n",
    "    y_output_4 = tf.add(xc, y_output_3)\n",
    "    net_dict[\"yc_output{0}\".format(i)] = tf.reshape(y_output_4, [batch_size, N * Z], name='yc_output'.format(i))\n",
    "    # calculate loss\n",
    "    net_dict[\"lossc{0}\".format(i)] = 1.0 * tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=yc,\n",
    "                                                             logits=net_dict[\"yc_output{0}\".format(i)]), name='lossc'.format(i))\n",
    "    # AdamOptimizer\n",
    "    net_dict[\"train_stepc{0}\".format(i)] = tf.train.AdamOptimizer(learning_rate=\n",
    "                                                                 learning_rate).minimize(net_dict[\"lossc{0}\".format(i)],\n",
    "                                 var_list = [net_dict[\"Weights_Var{0}\".format(i)], net_dict[\"Biases_Var{0}\".format(i)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca089ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the decoding neural network of Z=6\n",
    "Z = 6\n",
    "xd = tf.placeholder(tf.float32, shape=[batch_size, N, Z], name='xd')\n",
    "yd = tf.placeholder(tf.float32, shape=[batch_size, N * Z], name='yd')\n",
    "xd_input = tf.transpose(xd, [0, 2, 1])\n",
    "net_dict[\"LLRd{0}\".format(0)] = tf.zeros((batch_size, Z, sum_edge), dtype=tf.float32)\n",
    "for i in range(0, iters_max, 1):\n",
    "    # variable node update\n",
    "    x0 = tf.matmul(xd_input, W_skipconn2even)\n",
    "    x1 = tf.matmul(net_dict[\"LLRd{0}\".format(i)], W_odd2even)\n",
    "    x2 = tf.add(x0, x1)\n",
    "    x2 = tf.transpose(x2, [0, 2, 1])\n",
    "    x2 = tf.reshape(x2, [batch_size, neurons_per_odd_layer * Z])\n",
    "    x2 = tf.matmul(x2, Lift_Matrix1[3].transpose())\n",
    "    x2 = tf.reshape(x2, [batch_size, neurons_per_odd_layer, Z])\n",
    "    x2 = tf.transpose(x2, [0, 2, 1])\n",
    "    x_tile = tf.tile(x2, multiples=[1, 1, neurons_per_odd_layer])\n",
    "    W_input_reshape = tf.reshape(W_even2odd.transpose(), [-1])\n",
    "    # check node update\n",
    "    x_tile_mul = tf.multiply(x_tile, W_input_reshape)\n",
    "    x2_1 = tf.reshape(x_tile_mul, [batch_size, Z, neurons_per_odd_layer, neurons_per_odd_layer])\n",
    "    x2_abs = tf.add(tf.abs(x2_1), 100 * (1 - tf.to_float(tf.abs(x2_1) > 0)))\n",
    "    x3 = tf.reduce_min(x2_abs, axis=3)\n",
    "    x2_2 = -x2_1\n",
    "    x4 = tf.add(tf.zeros((batch_size, Z, neurons_per_odd_layer, neurons_per_odd_layer)),\n",
    "                1 - 2 * tf.to_float(x2_2 < 0))\n",
    "    x4_prod = -tf.reduce_prod(x4, axis=3)\n",
    "    x_output_0 = tf.multiply(x3, tf.sign(x4_prod))\n",
    "    x_output_0 = tf.transpose(x_output_0, [0, 2, 1])\n",
    "    x_output_0 = tf.reshape(x_output_0, [batch_size, Z * neurons_per_odd_layer])\n",
    "    x_output_0 = tf.matmul(x_output_0, Lift_Matrix2[3])\n",
    "    x_output_0 = tf.reshape(x_output_0, [batch_size, neurons_per_odd_layer, Z])\n",
    "    x_output_0 = tf.transpose(x_output_0, [0, 2, 1])\n",
    "    # add learnable parameters\n",
    "    x_output_1 = tf.add(tf.multiply(tf.abs(x_output_0), net_dict[\"Weights_Var{0}\".format(i)]),\n",
    "                        net_dict[\"Biases_Var{0}\".format(i)])\n",
    "    x_output_1 = tf.multiply(x_output_1, tf.to_float(x_output_1 > 0))\n",
    "    net_dict[\"LLRd{0}\".format(i + 1)] = tf.multiply(x_output_1, tf.sign(x_output_0))\n",
    "    # output\n",
    "    y_output_2 = tf.matmul(net_dict[\"LLRd{0}\".format(i + 1)], W_output)\n",
    "    y_output_3 = tf.transpose(y_output_2, [0, 2, 1])\n",
    "    y_output_4 = tf.add(xd, y_output_3)\n",
    "    net_dict[\"yd_output{0}\".format(i)] = tf.reshape(y_output_4, [batch_size, N * Z], name='yd_output'.format(i))\n",
    "    # calculate loss\n",
    "    net_dict[\"lossd{0}\".format(i)] = 1.0 * tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=yd,\n",
    "                                                                            logits=net_dict[\"yd_output{0}\".format(i)]),\n",
    "                                                                             name='lossd'.format(i))\n",
    "    # AdamOptimizer\n",
    "    net_dict[\"train_stepd{0}\".format(i)] = tf.train.AdamOptimizer(learning_rate=\n",
    "                                                                  learning_rate).minimize(net_dict[\"lossd{0}\".format(i)],\n",
    "                                                                  var_list=[net_dict[\"Weights_Var{0}\".format(i)], net_dict[\"Biases_Var{0}\".format(i)]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888b0757",
   "metadata": {},
   "source": [
    "ShapeLayer: I think iters_max and iter used to make same network parallelly\n",
    "\n",
    "GitHub Copilot: Yes, exactly! Let me explain how `iters_max` and `iter` are used to create parallel network structures:\n",
    "\n",
    "1. **Network Structure (`iters_max = 25`)**:\n",
    "```python\n",
    "# Creates 25 identical network layers, each with its own trainable parameters\n",
    "for i in range(0, iters_max, 1):\n",
    "    net_dict[f\"Weights_Var{i}\"] = tf.Variable(Weights_Var.copy())\n",
    "    net_dict[f\"Biases_Var{i}\"] = tf.Variable(Biases_Var.copy())\n",
    "```\n",
    "\n",
    "2. **Network Operation (`iter` in training)**:\n",
    "```python\n",
    "# Each iteration processes through all 25 layers sequentially\n",
    "for iter in range(0, iters_max, 1):\n",
    "    for i in range(0, num_of_batch, 1):\n",
    "        # Process data through the network layers\n",
    "        y_pred, train_loss, _ = sess.run([\n",
    "            net_dict[f\"ya_output{iter}\"], \n",
    "            net_dict[f\"lossa{iter}\"],\n",
    "            net_dict[f\"train_stepa{iter}\"]\n",
    "        ])\n",
    "```\n",
    "\n",
    "This creates a structure where:\n",
    "- Each iteration represents one message-passing step in LDPC decoding\n",
    "- All 25 iterations are implemented as separate but identical network layers\n",
    "- Each layer has its own trainable parameters (`Weights_Var{i}`, `Biases_Var{i}`)\n",
    "- Data flows through these layers sequentially during decoding\n",
    "\n",
    "So while it looks like parallel networks, it's actually implementing an unrolled iterative decoding process where each iteration is a separate layer in the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c8232d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 15:57:11.516234: W tensorflow/c/c_api.cc:304] Operation '{name:'Biases_Var_24/Adam_7/Assign' id:23329 op device:{requested: '', assigned: ''} def:{{{node Biases_Var_24/Adam_7/Assign}} = Assign[T=DT_FLOAT, _class=[\"loc:@Biases_Var_24\"], _has_manual_control_dependencies=true, use_locking=true, validate_shape=true](Biases_Var_24/Adam_7, Biases_Var_24/Adam_7/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2025-04-08 15:57:17.931976: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-04-08 15:57:24.630145: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: [1/25]\tepoch: [0/50000]\tloss: 0.03929375857114792\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 15:57:30.040094: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-04-08 15:57:34.372280: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-04-08 15:57:38.048000: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: [1/25]\tepoch: [200/50000]\tloss: 0.03222029283642769\t\n",
      "iteration: [1/25]\tepoch: [400/50000]\tloss: 0.027924757450819016\t\n",
      "iteration: [1/25]\tepoch: [600/50000]\tloss: 0.025774626061320305\t\n",
      "iteration: [1/25]\tepoch: [800/50000]\tloss: 0.030797893181443214\t\n",
      "iteration: [1/25]\tepoch: [1000/50000]\tloss: 0.029863638803362846\t\n",
      "iteration: [1/25]\tepoch: [1200/50000]\tloss: 0.029537910595536232\t\n",
      "iteration: [1/25]\tepoch: [1400/50000]\tloss: 0.026981906965374947\t\n",
      "iteration: [1/25]\tepoch: [1600/50000]\tloss: 0.028509877622127533\t\n",
      "iteration: [1/25]\tepoch: [1800/50000]\tloss: 0.0294734388589859\t\n",
      "iteration: [1/25]\tepoch: [2000/50000]\tloss: 0.030388902872800827\t\n",
      "iteration: [1/25]\tepoch: [2200/50000]\tloss: 0.02944001741707325\t\n",
      "iteration: [1/25]\tepoch: [2400/50000]\tloss: 0.03274635598063469\t\n",
      "iteration: [1/25]\tepoch: [2600/50000]\tloss: 0.027524743229150772\t\n",
      "iteration: [1/25]\tepoch: [2800/50000]\tloss: 0.030912762507796288\t\n",
      "iteration: [1/25]\tepoch: [3000/50000]\tloss: 0.031019659712910652\t\n",
      "iteration: [1/25]\tepoch: [3200/50000]\tloss: 0.027896422892808914\t\n",
      "iteration: [1/25]\tepoch: [3400/50000]\tloss: 0.026392510160803795\t\n",
      "iteration: [1/25]\tepoch: [3600/50000]\tloss: 0.029016751796007156\t\n",
      "iteration: [1/25]\tepoch: [3800/50000]\tloss: 0.02661815658211708\t\n",
      "iteration: [1/25]\tepoch: [4000/50000]\tloss: 0.02798682078719139\t\n",
      "iteration: [1/25]\tepoch: [4200/50000]\tloss: 0.032565344125032425\t\n",
      "iteration: [1/25]\tepoch: [4400/50000]\tloss: 0.029687626287341118\t\n",
      "iteration: [1/25]\tepoch: [4600/50000]\tloss: 0.03077019564807415\t\n",
      "iteration: [1/25]\tepoch: [4800/50000]\tloss: 0.03041495755314827\t\n",
      "iteration: [1/25]\tepoch: [5000/50000]\tloss: 0.031325627118349075\t\n",
      "iteration: [1/25]\tepoch: [5200/50000]\tloss: 0.03297712653875351\t\n",
      "iteration: [1/25]\tepoch: [5400/50000]\tloss: 0.027721181511878967\t\n",
      "iteration: [1/25]\tepoch: [5600/50000]\tloss: 0.029992666095495224\t\n",
      "iteration: [1/25]\tepoch: [5800/50000]\tloss: 0.028970882296562195\t\n",
      "iteration: [1/25]\tepoch: [6000/50000]\tloss: 0.030083855614066124\t\n",
      "iteration: [1/25]\tepoch: [6200/50000]\tloss: 0.03137817978858948\t\n",
      "iteration: [1/25]\tepoch: [6400/50000]\tloss: 0.031330399215221405\t\n",
      "iteration: [1/25]\tepoch: [6600/50000]\tloss: 0.02660112828016281\t\n",
      "iteration: [1/25]\tepoch: [6800/50000]\tloss: 0.030603785067796707\t\n",
      "iteration: [1/25]\tepoch: [7000/50000]\tloss: 0.02810502052307129\t\n",
      "iteration: [1/25]\tepoch: [7200/50000]\tloss: 0.029461635276675224\t\n",
      "iteration: [1/25]\tepoch: [7400/50000]\tloss: 0.03223472461104393\t\n",
      "iteration: [1/25]\tepoch: [7600/50000]\tloss: 0.0310493316501379\t\n",
      "iteration: [1/25]\tepoch: [7800/50000]\tloss: 0.029580937698483467\t\n",
      "iteration: [1/25]\tepoch: [8000/50000]\tloss: 0.028863657265901566\t\n",
      "iteration: [1/25]\tepoch: [8200/50000]\tloss: 0.03143778443336487\t\n",
      "iteration: [1/25]\tepoch: [8400/50000]\tloss: 0.027859656140208244\t\n",
      "iteration: [1/25]\tepoch: [8600/50000]\tloss: 0.029851479455828667\t\n",
      "iteration: [1/25]\tepoch: [8800/50000]\tloss: 0.02721247635781765\t\n",
      "iteration: [1/25]\tepoch: [9000/50000]\tloss: 0.028063060715794563\t\n",
      "iteration: [1/25]\tepoch: [9200/50000]\tloss: 0.028563333675265312\t\n",
      "iteration: [1/25]\tepoch: [9400/50000]\tloss: 0.029391959309577942\t\n",
      "iteration: [1/25]\tepoch: [9600/50000]\tloss: 0.030225463211536407\t\n",
      "iteration: [1/25]\tepoch: [9800/50000]\tloss: 0.029677484184503555\t\n",
      "iteration: [1/25]\tepoch: [10000/50000]\tloss: 0.02993002161383629\t\n",
      "iteration: [1/25]\tepoch: [10200/50000]\tloss: 0.027068257331848145\t\n",
      "iteration: [1/25]\tepoch: [10400/50000]\tloss: 0.02970227412879467\t\n",
      "iteration: [1/25]\tepoch: [10600/50000]\tloss: 0.029967650771141052\t\n",
      "iteration: [1/25]\tepoch: [10800/50000]\tloss: 0.0310568418353796\t\n",
      "iteration: [1/25]\tepoch: [11000/50000]\tloss: 0.03376958519220352\t\n",
      "iteration: [1/25]\tepoch: [11200/50000]\tloss: 0.026998324319720268\t\n",
      "iteration: [1/25]\tepoch: [11400/50000]\tloss: 0.032290488481521606\t\n",
      "iteration: [1/25]\tepoch: [11600/50000]\tloss: 0.03125360608100891\t\n",
      "iteration: [1/25]\tepoch: [11800/50000]\tloss: 0.02748330868780613\t\n",
      "iteration: [1/25]\tepoch: [12000/50000]\tloss: 0.028232838958501816\t\n",
      "iteration: [1/25]\tepoch: [12200/50000]\tloss: 0.03194195777177811\t\n",
      "iteration: [1/25]\tepoch: [12400/50000]\tloss: 0.030948355793952942\t\n",
      "iteration: [1/25]\tepoch: [12600/50000]\tloss: 0.02864016592502594\t\n",
      "iteration: [1/25]\tepoch: [12800/50000]\tloss: 0.030977120622992516\t\n",
      "iteration: [1/25]\tepoch: [13000/50000]\tloss: 0.03068596124649048\t\n",
      "iteration: [1/25]\tepoch: [13200/50000]\tloss: 0.029090141877532005\t\n",
      "iteration: [1/25]\tepoch: [13400/50000]\tloss: 0.03065057098865509\t\n",
      "iteration: [1/25]\tepoch: [13600/50000]\tloss: 0.028184764087200165\t\n",
      "iteration: [1/25]\tepoch: [13800/50000]\tloss: 0.028924033045768738\t\n",
      "iteration: [1/25]\tepoch: [14000/50000]\tloss: 0.030894119292497635\t\n",
      "iteration: [1/25]\tepoch: [14200/50000]\tloss: 0.029274675995111465\t\n",
      "iteration: [1/25]\tepoch: [14400/50000]\tloss: 0.02796219475567341\t\n",
      "iteration: [1/25]\tepoch: [14600/50000]\tloss: 0.029300199821591377\t\n",
      "iteration: [1/25]\tepoch: [14800/50000]\tloss: 0.033640056848526\t\n",
      "iteration: [1/25]\tepoch: [15000/50000]\tloss: 0.029609229415655136\t\n",
      "iteration: [1/25]\tepoch: [15200/50000]\tloss: 0.02963099256157875\t\n",
      "iteration: [1/25]\tepoch: [15400/50000]\tloss: 0.03088163584470749\t\n",
      "iteration: [1/25]\tepoch: [15600/50000]\tloss: 0.029095550999045372\t\n",
      "iteration: [1/25]\tepoch: [15800/50000]\tloss: 0.03435296192765236\t\n",
      "iteration: [1/25]\tepoch: [16000/50000]\tloss: 0.033944837749004364\t\n",
      "iteration: [1/25]\tepoch: [16200/50000]\tloss: 0.028688881546258926\t\n",
      "iteration: [1/25]\tepoch: [16400/50000]\tloss: 0.029035981744527817\t\n",
      "iteration: [1/25]\tepoch: [16600/50000]\tloss: 0.030090784654021263\t\n",
      "iteration: [1/25]\tepoch: [16800/50000]\tloss: 0.030409442260861397\t\n",
      "iteration: [1/25]\tepoch: [17000/50000]\tloss: 0.03312588483095169\t\n",
      "iteration: [1/25]\tepoch: [17200/50000]\tloss: 0.02722730115056038\t\n",
      "iteration: [1/25]\tepoch: [17400/50000]\tloss: 0.034130509942770004\t\n",
      "iteration: [1/25]\tepoch: [17600/50000]\tloss: 0.031127214431762695\t\n",
      "iteration: [1/25]\tepoch: [17800/50000]\tloss: 0.02602817490696907\t\n",
      "iteration: [1/25]\tepoch: [18000/50000]\tloss: 0.029771829023957253\t\n",
      "iteration: [1/25]\tepoch: [18200/50000]\tloss: 0.032107774168252945\t\n",
      "iteration: [1/25]\tepoch: [18400/50000]\tloss: 0.032160401344299316\t\n",
      "iteration: [1/25]\tepoch: [18600/50000]\tloss: 0.029539993032813072\t\n",
      "iteration: [1/25]\tepoch: [18800/50000]\tloss: 0.03083391860127449\t\n",
      "iteration: [1/25]\tepoch: [19000/50000]\tloss: 0.028685538098216057\t\n",
      "iteration: [1/25]\tepoch: [19200/50000]\tloss: 0.029908498749136925\t\n",
      "iteration: [1/25]\tepoch: [19400/50000]\tloss: 0.03038991242647171\t\n",
      "iteration: [1/25]\tepoch: [19600/50000]\tloss: 0.020269865170121193\t\n",
      "iteration: [1/25]\tepoch: [19800/50000]\tloss: 0.025807294994592667\t\n",
      "iteration: [1/25]\tepoch: [20000/50000]\tloss: 0.031727440655231476\t\n",
      "iteration: [1/25]\tepoch: [20200/50000]\tloss: 0.03250398859381676\t\n",
      "iteration: [1/25]\tepoch: [20400/50000]\tloss: 0.029325036332011223\t\n",
      "iteration: [1/25]\tepoch: [20600/50000]\tloss: 0.031353168189525604\t\n",
      "iteration: [1/25]\tepoch: [20800/50000]\tloss: 0.02987630106508732\t\n",
      "iteration: [1/25]\tepoch: [21000/50000]\tloss: 0.03000013530254364\t\n",
      "iteration: [1/25]\tepoch: [21200/50000]\tloss: 0.029155148193240166\t\n",
      "iteration: [1/25]\tepoch: [21400/50000]\tloss: 0.03359736129641533\t\n",
      "iteration: [1/25]\tepoch: [21600/50000]\tloss: 0.02966204471886158\t\n",
      "iteration: [1/25]\tepoch: [21800/50000]\tloss: 0.03135183826088905\t\n",
      "iteration: [1/25]\tepoch: [22000/50000]\tloss: 0.0319613479077816\t\n",
      "iteration: [1/25]\tepoch: [22200/50000]\tloss: 0.027580372989177704\t\n",
      "iteration: [1/25]\tepoch: [22400/50000]\tloss: 0.03175659477710724\t\n",
      "iteration: [1/25]\tepoch: [22600/50000]\tloss: 0.02661391720175743\t\n",
      "iteration: [1/25]\tepoch: [22800/50000]\tloss: 0.02597804367542267\t\n",
      "iteration: [1/25]\tepoch: [23000/50000]\tloss: 0.030211133882403374\t\n",
      "iteration: [1/25]\tepoch: [23200/50000]\tloss: 0.03029831498861313\t\n",
      "iteration: [1/25]\tepoch: [23400/50000]\tloss: 0.022097699344158173\t\n",
      "iteration: [1/25]\tepoch: [23600/50000]\tloss: 0.031223531812429428\t\n",
      "iteration: [1/25]\tepoch: [23800/50000]\tloss: 0.030929865315556526\t\n",
      "iteration: [1/25]\tepoch: [24000/50000]\tloss: 0.03130456805229187\t\n",
      "iteration: [1/25]\tepoch: [24200/50000]\tloss: 0.03072892501950264\t\n",
      "iteration: [1/25]\tepoch: [24400/50000]\tloss: 0.03344358876347542\t\n",
      "iteration: [1/25]\tepoch: [24600/50000]\tloss: 0.030222725123167038\t\n",
      "iteration: [1/25]\tepoch: [24800/50000]\tloss: 0.030080782249569893\t\n",
      "iteration: [1/25]\tepoch: [25000/50000]\tloss: 0.03203538432717323\t\n",
      "iteration: [1/25]\tepoch: [25200/50000]\tloss: 0.028469299897551537\t\n",
      "iteration: [1/25]\tepoch: [25400/50000]\tloss: 0.0314657986164093\t\n",
      "iteration: [1/25]\tepoch: [25600/50000]\tloss: 0.02861562930047512\t\n",
      "iteration: [1/25]\tepoch: [25800/50000]\tloss: 0.031562719494104385\t\n",
      "iteration: [1/25]\tepoch: [26000/50000]\tloss: 0.03089403547346592\t\n",
      "iteration: [1/25]\tepoch: [26200/50000]\tloss: 0.029155980795621872\t\n",
      "iteration: [1/25]\tepoch: [26400/50000]\tloss: 0.027063174173235893\t\n",
      "iteration: [1/25]\tepoch: [26600/50000]\tloss: 0.031852059066295624\t\n",
      "iteration: [1/25]\tepoch: [26800/50000]\tloss: 0.027239063754677773\t\n",
      "iteration: [1/25]\tepoch: [27000/50000]\tloss: 0.02887769602239132\t\n",
      "iteration: [1/25]\tepoch: [27200/50000]\tloss: 0.03159168362617493\t\n",
      "iteration: [1/25]\tepoch: [27400/50000]\tloss: 0.027629096060991287\t\n",
      "iteration: [1/25]\tepoch: [27600/50000]\tloss: 0.031489577144384384\t\n",
      "iteration: [1/25]\tepoch: [27800/50000]\tloss: 0.03093537874519825\t\n",
      "iteration: [1/25]\tepoch: [28000/50000]\tloss: 0.03206904977560043\t\n",
      "iteration: [1/25]\tepoch: [28200/50000]\tloss: 0.03072251006960869\t\n",
      "iteration: [1/25]\tepoch: [28400/50000]\tloss: 0.030017832294106483\t\n",
      "iteration: [1/25]\tepoch: [28600/50000]\tloss: 0.029750771820545197\t\n",
      "iteration: [1/25]\tepoch: [28800/50000]\tloss: 0.03404007852077484\t\n",
      "iteration: [1/25]\tepoch: [29000/50000]\tloss: 0.031224682927131653\t\n",
      "iteration: [1/25]\tepoch: [29200/50000]\tloss: 0.030226487666368484\t\n",
      "iteration: [1/25]\tepoch: [29400/50000]\tloss: 0.036004699766635895\t\n",
      "iteration: [1/25]\tepoch: [29600/50000]\tloss: 0.027818122878670692\t\n",
      "iteration: [1/25]\tepoch: [29800/50000]\tloss: 0.028788210824131966\t\n",
      "iteration: [1/25]\tepoch: [30000/50000]\tloss: 0.028792183846235275\t\n",
      "iteration: [1/25]\tepoch: [30200/50000]\tloss: 0.02915865369141102\t\n",
      "iteration: [1/25]\tepoch: [30400/50000]\tloss: 0.030420251190662384\t\n",
      "iteration: [1/25]\tepoch: [30600/50000]\tloss: 0.02883715182542801\t\n",
      "iteration: [1/25]\tepoch: [30800/50000]\tloss: 0.029274169355630875\t\n",
      "iteration: [1/25]\tepoch: [31000/50000]\tloss: 0.028771286830306053\t\n",
      "iteration: [1/25]\tepoch: [31200/50000]\tloss: 0.03130223602056503\t\n",
      "iteration: [1/25]\tepoch: [31400/50000]\tloss: 0.028366370126605034\t\n",
      "iteration: [1/25]\tepoch: [31600/50000]\tloss: 0.03499266505241394\t\n",
      "iteration: [1/25]\tepoch: [31800/50000]\tloss: 0.026251882314682007\t\n",
      "iteration: [1/25]\tepoch: [32000/50000]\tloss: 0.031371381133794785\t\n",
      "iteration: [1/25]\tepoch: [32200/50000]\tloss: 0.032339584082365036\t\n",
      "iteration: [1/25]\tepoch: [32400/50000]\tloss: 0.02721531316637993\t\n",
      "iteration: [1/25]\tepoch: [32600/50000]\tloss: 0.02728353999555111\t\n",
      "iteration: [1/25]\tepoch: [32800/50000]\tloss: 0.03076670505106449\t\n",
      "iteration: [1/25]\tepoch: [33000/50000]\tloss: 0.029476534575223923\t\n",
      "iteration: [1/25]\tepoch: [33200/50000]\tloss: 0.02783001773059368\t\n",
      "iteration: [1/25]\tepoch: [33400/50000]\tloss: 0.035705532878637314\t\n",
      "iteration: [1/25]\tepoch: [33600/50000]\tloss: 0.030558748170733452\t\n",
      "iteration: [1/25]\tepoch: [33800/50000]\tloss: 0.030401606112718582\t\n",
      "iteration: [1/25]\tepoch: [34000/50000]\tloss: 0.030868589878082275\t\n",
      "iteration: [1/25]\tepoch: [34200/50000]\tloss: 0.03242848441004753\t\n",
      "iteration: [1/25]\tepoch: [34400/50000]\tloss: 0.029789431020617485\t\n",
      "iteration: [1/25]\tepoch: [34600/50000]\tloss: 0.03271696716547012\t\n",
      "iteration: [1/25]\tepoch: [34800/50000]\tloss: 0.028918970376253128\t\n",
      "iteration: [1/25]\tepoch: [35000/50000]\tloss: 0.03107845038175583\t\n",
      "iteration: [1/25]\tepoch: [35200/50000]\tloss: 0.0307916309684515\t\n",
      "iteration: [1/25]\tepoch: [35400/50000]\tloss: 0.027764497324824333\t\n",
      "iteration: [1/25]\tepoch: [35600/50000]\tloss: 0.031061723828315735\t\n",
      "iteration: [1/25]\tepoch: [35800/50000]\tloss: 0.03275279700756073\t\n",
      "iteration: [1/25]\tepoch: [36000/50000]\tloss: 0.030102642253041267\t\n",
      "iteration: [1/25]\tepoch: [36200/50000]\tloss: 0.03085429221391678\t\n",
      "iteration: [1/25]\tepoch: [36400/50000]\tloss: 0.029559442773461342\t\n",
      "iteration: [1/25]\tepoch: [36600/50000]\tloss: 0.0314081609249115\t\n",
      "iteration: [1/25]\tepoch: [36800/50000]\tloss: 0.03286344185471535\t\n",
      "iteration: [1/25]\tepoch: [37000/50000]\tloss: 0.028675278648734093\t\n",
      "iteration: [1/25]\tepoch: [37200/50000]\tloss: 0.026945194229483604\t\n",
      "iteration: [1/25]\tepoch: [37400/50000]\tloss: 0.028165200725197792\t\n",
      "iteration: [1/25]\tepoch: [37600/50000]\tloss: 0.0314367301762104\t\n",
      "iteration: [1/25]\tepoch: [37800/50000]\tloss: 0.02819354645907879\t\n",
      "iteration: [1/25]\tepoch: [38000/50000]\tloss: 0.029569773003458977\t\n",
      "iteration: [1/25]\tepoch: [38200/50000]\tloss: 0.028518592938780785\t\n",
      "iteration: [1/25]\tepoch: [38400/50000]\tloss: 0.03454391285777092\t\n",
      "iteration: [1/25]\tepoch: [38600/50000]\tloss: 0.029428381472826004\t\n",
      "iteration: [1/25]\tepoch: [38800/50000]\tloss: 0.028883695602416992\t\n",
      "iteration: [1/25]\tepoch: [39000/50000]\tloss: 0.03169718384742737\t\n",
      "iteration: [1/25]\tepoch: [39200/50000]\tloss: 0.02907073311507702\t\n",
      "iteration: [1/25]\tepoch: [39400/50000]\tloss: 0.02692074328660965\t\n",
      "iteration: [1/25]\tepoch: [39600/50000]\tloss: 0.030307872220873833\t\n",
      "iteration: [1/25]\tepoch: [39800/50000]\tloss: 0.03072655014693737\t\n",
      "iteration: [1/25]\tepoch: [40000/50000]\tloss: 0.028450237587094307\t\n",
      "iteration: [1/25]\tepoch: [40200/50000]\tloss: 0.02850835584104061\t\n",
      "iteration: [1/25]\tepoch: [40400/50000]\tloss: 0.029739825055003166\t\n",
      "iteration: [1/25]\tepoch: [40600/50000]\tloss: 0.028355900198221207\t\n",
      "iteration: [1/25]\tepoch: [40800/50000]\tloss: 0.031333185732364655\t\n",
      "iteration: [1/25]\tepoch: [41000/50000]\tloss: 0.023678142577409744\t\n",
      "iteration: [1/25]\tepoch: [41200/50000]\tloss: 0.030839474871754646\t\n",
      "iteration: [1/25]\tepoch: [41400/50000]\tloss: 0.028796296566724777\t\n",
      "iteration: [1/25]\tepoch: [41600/50000]\tloss: 0.029420336708426476\t\n",
      "iteration: [1/25]\tepoch: [41800/50000]\tloss: 0.02764398790895939\t\n",
      "iteration: [1/25]\tepoch: [42000/50000]\tloss: 0.027455341070890427\t\n",
      "iteration: [1/25]\tepoch: [42200/50000]\tloss: 0.027170304208993912\t\n",
      "iteration: [1/25]\tepoch: [42400/50000]\tloss: 0.028720734640955925\t\n",
      "iteration: [1/25]\tepoch: [42600/50000]\tloss: 0.03313620388507843\t\n",
      "iteration: [1/25]\tepoch: [42800/50000]\tloss: 0.030483704060316086\t\n",
      "iteration: [1/25]\tepoch: [43000/50000]\tloss: 0.027709996327757835\t\n",
      "iteration: [1/25]\tepoch: [43200/50000]\tloss: 0.03396168723702431\t\n",
      "iteration: [1/25]\tepoch: [43400/50000]\tloss: 0.028965197503566742\t\n",
      "iteration: [1/25]\tepoch: [43600/50000]\tloss: 0.03082859329879284\t\n",
      "iteration: [1/25]\tepoch: [43800/50000]\tloss: 0.027934638783335686\t\n",
      "iteration: [1/25]\tepoch: [44000/50000]\tloss: 0.030508488416671753\t\n",
      "iteration: [1/25]\tepoch: [44200/50000]\tloss: 0.028018366545438766\t\n",
      "iteration: [1/25]\tepoch: [44400/50000]\tloss: 0.028434982523322105\t\n",
      "iteration: [1/25]\tepoch: [44600/50000]\tloss: 0.028788134455680847\t\n",
      "iteration: [1/25]\tepoch: [44800/50000]\tloss: 0.03337796777486801\t\n",
      "iteration: [1/25]\tepoch: [45000/50000]\tloss: 0.03013739362359047\t\n",
      "iteration: [1/25]\tepoch: [45200/50000]\tloss: 0.0302894189953804\t\n",
      "iteration: [1/25]\tepoch: [45400/50000]\tloss: 0.031101327389478683\t\n",
      "iteration: [1/25]\tepoch: [45600/50000]\tloss: 0.03134821355342865\t\n",
      "iteration: [1/25]\tepoch: [45800/50000]\tloss: 0.027667848393321037\t\n",
      "iteration: [1/25]\tepoch: [46000/50000]\tloss: 0.029403885826468468\t\n",
      "iteration: [1/25]\tepoch: [46200/50000]\tloss: 0.026632729917764664\t\n",
      "iteration: [1/25]\tepoch: [46400/50000]\tloss: 0.026159629225730896\t\n",
      "iteration: [1/25]\tepoch: [46600/50000]\tloss: 0.03262985125184059\t\n",
      "iteration: [1/25]\tepoch: [46800/50000]\tloss: 0.028551170602440834\t\n",
      "iteration: [1/25]\tepoch: [47000/50000]\tloss: 0.031872108578681946\t\n",
      "iteration: [1/25]\tepoch: [47200/50000]\tloss: 0.02911270782351494\t\n",
      "iteration: [1/25]\tepoch: [47400/50000]\tloss: 0.02864275500178337\t\n",
      "iteration: [1/25]\tepoch: [47600/50000]\tloss: 0.02937268279492855\t\n",
      "iteration: [1/25]\tepoch: [47800/50000]\tloss: 0.02894706092774868\t\n",
      "iteration: [1/25]\tepoch: [48000/50000]\tloss: 0.031102072447538376\t\n",
      "iteration: [1/25]\tepoch: [48200/50000]\tloss: 0.030343469232320786\t\n",
      "iteration: [1/25]\tepoch: [48400/50000]\tloss: 0.03050898388028145\t\n",
      "iteration: [1/25]\tepoch: [48600/50000]\tloss: 0.031141260638833046\t\n",
      "iteration: [1/25]\tepoch: [48800/50000]\tloss: 0.027772128582000732\t\n",
      "iteration: [1/25]\tepoch: [49000/50000]\tloss: 0.031188927590847015\t\n",
      "iteration: [1/25]\tepoch: [49200/50000]\tloss: 0.024299046024680138\t\n",
      "iteration: [1/25]\tepoch: [49400/50000]\tloss: 0.02839600294828415\t\n",
      "iteration: [1/25]\tepoch: [49600/50000]\tloss: 0.02929474040865898\t\n",
      "iteration: [1/25]\tepoch: [49800/50000]\tloss: 0.031133189797401428\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 16:41:21.900235: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-04-08 16:41:24.489153: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: [2/25]\tepoch: [0/50000]\tloss: 0.040332186967134476\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 16:41:27.714819: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-04-08 16:41:30.833312: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2025-04-08 16:41:36.398767: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: [2/25]\tepoch: [200/50000]\tloss: 0.03405211493372917\t\n",
      "iteration: [2/25]\tepoch: [400/50000]\tloss: 0.021251875907182693\t\n",
      "iteration: [2/25]\tepoch: [600/50000]\tloss: 0.03143373504281044\t\n",
      "iteration: [2/25]\tepoch: [800/50000]\tloss: 0.024746891111135483\t\n",
      "iteration: [2/25]\tepoch: [1000/50000]\tloss: 0.02922142669558525\t\n",
      "iteration: [2/25]\tepoch: [1200/50000]\tloss: 0.028915105387568474\t\n",
      "iteration: [2/25]\tepoch: [1400/50000]\tloss: 0.026309970766305923\t\n",
      "iteration: [2/25]\tepoch: [1600/50000]\tloss: 0.03132776916027069\t\n",
      "iteration: [2/25]\tepoch: [1800/50000]\tloss: 0.024209441617131233\t\n",
      "iteration: [2/25]\tepoch: [2000/50000]\tloss: 0.027123210951685905\t\n",
      "iteration: [2/25]\tepoch: [2200/50000]\tloss: 0.02845221385359764\t\n",
      "iteration: [2/25]\tepoch: [2400/50000]\tloss: 0.030991237610578537\t\n",
      "iteration: [2/25]\tepoch: [2600/50000]\tloss: 0.026516322046518326\t\n",
      "iteration: [2/25]\tepoch: [2800/50000]\tloss: 0.022559059783816338\t\n",
      "iteration: [2/25]\tepoch: [3000/50000]\tloss: 0.031156616285443306\t\n",
      "iteration: [2/25]\tepoch: [3200/50000]\tloss: 0.03115290403366089\t\n",
      "iteration: [2/25]\tepoch: [3400/50000]\tloss: 0.025904716923832893\t\n",
      "iteration: [2/25]\tepoch: [3600/50000]\tloss: 0.02965991385281086\t\n",
      "iteration: [2/25]\tepoch: [3800/50000]\tloss: 0.031118784099817276\t\n",
      "iteration: [2/25]\tepoch: [4000/50000]\tloss: 0.030309680849313736\t\n",
      "iteration: [2/25]\tepoch: [4200/50000]\tloss: 0.04731113463640213\t\n",
      "iteration: [2/25]\tepoch: [4400/50000]\tloss: 0.030596895143389702\t\n",
      "iteration: [2/25]\tepoch: [4600/50000]\tloss: 0.03175932168960571\t\n",
      "iteration: [2/25]\tepoch: [4800/50000]\tloss: 0.027154065668582916\t\n",
      "iteration: [2/25]\tepoch: [5000/50000]\tloss: 0.025239918380975723\t\n",
      "iteration: [2/25]\tepoch: [5200/50000]\tloss: 0.028839539736509323\t\n",
      "iteration: [2/25]\tepoch: [5400/50000]\tloss: 0.026553746312856674\t\n",
      "iteration: [2/25]\tepoch: [5600/50000]\tloss: 0.026436185464262962\t\n",
      "iteration: [2/25]\tepoch: [5800/50000]\tloss: 0.031081967055797577\t\n",
      "iteration: [2/25]\tepoch: [6000/50000]\tloss: 0.03217373043298721\t\n",
      "iteration: [2/25]\tepoch: [6200/50000]\tloss: 0.02807150036096573\t\n",
      "iteration: [2/25]\tepoch: [6400/50000]\tloss: 0.03364528343081474\t\n",
      "iteration: [2/25]\tepoch: [6600/50000]\tloss: 0.030820518732070923\t\n",
      "iteration: [2/25]\tepoch: [6800/50000]\tloss: 0.030294982716441154\t\n",
      "iteration: [2/25]\tepoch: [7000/50000]\tloss: 0.02608683705329895\t\n",
      "iteration: [2/25]\tepoch: [7200/50000]\tloss: 0.017615973949432373\t\n",
      "iteration: [2/25]\tepoch: [7400/50000]\tloss: 0.03204340487718582\t\n",
      "iteration: [2/25]\tepoch: [7600/50000]\tloss: 0.03401175141334534\t\n",
      "iteration: [2/25]\tepoch: [7800/50000]\tloss: 0.016528474166989326\t\n",
      "iteration: [2/25]\tepoch: [8000/50000]\tloss: 0.02985619194805622\t\n",
      "iteration: [2/25]\tepoch: [8200/50000]\tloss: 0.03583124652504921\t\n",
      "iteration: [2/25]\tepoch: [8400/50000]\tloss: 0.038274142891168594\t\n",
      "iteration: [2/25]\tepoch: [8600/50000]\tloss: 0.03250589966773987\t\n",
      "iteration: [2/25]\tepoch: [8800/50000]\tloss: 0.02987966313958168\t\n",
      "iteration: [2/25]\tepoch: [9000/50000]\tloss: 0.037221528589725494\t\n",
      "iteration: [2/25]\tepoch: [9200/50000]\tloss: 0.025487370789051056\t\n",
      "iteration: [2/25]\tepoch: [9400/50000]\tloss: 0.040575671941041946\t\n",
      "iteration: [2/25]\tepoch: [9600/50000]\tloss: 0.023000085726380348\t\n",
      "iteration: [2/25]\tepoch: [9800/50000]\tloss: 0.029628818854689598\t\n",
      "iteration: [2/25]\tepoch: [10000/50000]\tloss: 0.036466773599386215\t\n",
      "iteration: [2/25]\tepoch: [10200/50000]\tloss: 0.02557959407567978\t\n",
      "iteration: [2/25]\tepoch: [10400/50000]\tloss: 0.02715936489403248\t\n",
      "iteration: [2/25]\tepoch: [10600/50000]\tloss: 0.025195268914103508\t\n",
      "iteration: [2/25]\tepoch: [10800/50000]\tloss: 0.030118808150291443\t\n",
      "iteration: [2/25]\tepoch: [11000/50000]\tloss: 0.03135192021727562\t\n",
      "iteration: [2/25]\tepoch: [11200/50000]\tloss: 0.03510158509016037\t\n",
      "iteration: [2/25]\tepoch: [11400/50000]\tloss: 0.030519314110279083\t\n",
      "iteration: [2/25]\tepoch: [11600/50000]\tloss: 0.03436831012368202\t\n",
      "iteration: [2/25]\tepoch: [11800/50000]\tloss: 0.023735173046588898\t\n",
      "iteration: [2/25]\tepoch: [12000/50000]\tloss: 0.02772102691233158\t\n",
      "iteration: [2/25]\tepoch: [12200/50000]\tloss: 0.02640065737068653\t\n",
      "iteration: [2/25]\tepoch: [12400/50000]\tloss: 0.02619895339012146\t\n",
      "iteration: [2/25]\tepoch: [12600/50000]\tloss: 0.02456614188849926\t\n",
      "iteration: [2/25]\tepoch: [12800/50000]\tloss: 0.029635649174451828\t\n",
      "iteration: [2/25]\tepoch: [13000/50000]\tloss: 0.029823748394846916\t\n",
      "iteration: [2/25]\tepoch: [13200/50000]\tloss: 0.02684970013797283\t\n",
      "iteration: [2/25]\tepoch: [13400/50000]\tloss: 0.026086585596203804\t\n",
      "iteration: [2/25]\tepoch: [13600/50000]\tloss: 0.03410543128848076\t\n",
      "iteration: [2/25]\tepoch: [13800/50000]\tloss: 0.02564297243952751\t\n",
      "iteration: [2/25]\tepoch: [14000/50000]\tloss: 0.02622261643409729\t\n",
      "iteration: [2/25]\tepoch: [14200/50000]\tloss: 0.027237847447395325\t\n",
      "iteration: [2/25]\tepoch: [14400/50000]\tloss: 0.028798768296837807\t\n",
      "iteration: [2/25]\tepoch: [14600/50000]\tloss: 0.03278079256415367\t\n",
      "iteration: [2/25]\tepoch: [14800/50000]\tloss: 0.027020016685128212\t\n",
      "iteration: [2/25]\tepoch: [15000/50000]\tloss: 0.025951072573661804\t\n",
      "iteration: [2/25]\tepoch: [15200/50000]\tloss: 0.02962583489716053\t\n",
      "iteration: [2/25]\tepoch: [15400/50000]\tloss: 0.027904188260436058\t\n",
      "iteration: [2/25]\tepoch: [15600/50000]\tloss: 0.024534722790122032\t\n",
      "iteration: [2/25]\tepoch: [15800/50000]\tloss: 0.030361352488398552\t\n",
      "iteration: [2/25]\tepoch: [16000/50000]\tloss: 0.03812877833843231\t\n",
      "iteration: [2/25]\tepoch: [16200/50000]\tloss: 0.028563806787133217\t\n",
      "iteration: [2/25]\tepoch: [16400/50000]\tloss: 0.027972277253866196\t\n",
      "iteration: [2/25]\tepoch: [16600/50000]\tloss: 0.029444117099046707\t\n",
      "iteration: [2/25]\tepoch: [16800/50000]\tloss: 0.03211936727166176\t\n",
      "iteration: [2/25]\tepoch: [17000/50000]\tloss: 0.03681972622871399\t\n",
      "iteration: [2/25]\tepoch: [17200/50000]\tloss: 0.028126828372478485\t\n",
      "iteration: [2/25]\tepoch: [17400/50000]\tloss: 0.03346535935997963\t\n",
      "iteration: [2/25]\tepoch: [17600/50000]\tloss: 0.032288867980241776\t\n",
      "iteration: [2/25]\tepoch: [17800/50000]\tloss: 0.034242380410432816\t\n",
      "iteration: [2/25]\tepoch: [18000/50000]\tloss: 0.022224988788366318\t\n",
      "iteration: [2/25]\tepoch: [18200/50000]\tloss: 0.025738658383488655\t\n",
      "iteration: [2/25]\tepoch: [18400/50000]\tloss: 0.026853591203689575\t\n",
      "iteration: [2/25]\tepoch: [18600/50000]\tloss: 0.025357689708471298\t\n",
      "iteration: [2/25]\tepoch: [18800/50000]\tloss: 0.026486875489354134\t\n",
      "iteration: [2/25]\tepoch: [19000/50000]\tloss: 0.03960825130343437\t\n",
      "iteration: [2/25]\tepoch: [19200/50000]\tloss: 0.03215683624148369\t\n",
      "iteration: [2/25]\tepoch: [19400/50000]\tloss: 0.03405303508043289\t\n",
      "iteration: [2/25]\tepoch: [19600/50000]\tloss: 0.03906899318099022\t\n",
      "iteration: [2/25]\tepoch: [19800/50000]\tloss: 0.029813293367624283\t\n",
      "iteration: [2/25]\tepoch: [20000/50000]\tloss: 0.028996793553233147\t\n",
      "iteration: [2/25]\tepoch: [20200/50000]\tloss: 0.02737400121986866\t\n",
      "iteration: [2/25]\tepoch: [20400/50000]\tloss: 0.032643672078847885\t\n",
      "iteration: [2/25]\tepoch: [20600/50000]\tloss: 0.02794245257973671\t\n",
      "iteration: [2/25]\tepoch: [20800/50000]\tloss: 0.02616005204617977\t\n",
      "iteration: [2/25]\tepoch: [21000/50000]\tloss: 0.03316963091492653\t\n",
      "iteration: [2/25]\tepoch: [21200/50000]\tloss: 0.03239987790584564\t\n",
      "iteration: [2/25]\tepoch: [21400/50000]\tloss: 0.026316387578845024\t\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m training_received_data, training_coded_bits \u001b[38;5;241m=\u001b[39m create_mix_epoch(SNR_set, wordRandom, noiseRandom, numOfWordSim_train,\n\u001b[1;32m     13\u001b[0m                                                                code_n, code_k, Z,\n\u001b[1;32m     14\u001b[0m                                                                Ldpc_GM[Z_type],\n\u001b[1;32m     15\u001b[0m                                                                train_on_zero_word)\n\u001b[1;32m     16\u001b[0m training_labels_for_mse \u001b[38;5;241m=\u001b[39m training_coded_bits\n\u001b[0;32m---> 17\u001b[0m y_pred, train_loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnet_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mya_output\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlossa\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mnet_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_stepa\u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mxa\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_received_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mya\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_labels_for_mse\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miteration: [\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     22\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch: [\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     23\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;132;01m{4}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, iters_max, i, num_of_batch, train_loss))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/tensorflow/python/client/session.py:969\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 969\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    971\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    972\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/tensorflow/python/client/session.py:1192\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1192\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1195\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/tensorflow/python/client/session.py:1372\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1369\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1372\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1375\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/tensorflow/python/client/session.py:1379\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1378\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1380\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1381\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/tensorflow/python/client/session.py:1362\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1360\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1361\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1362\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1363\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/jsac-ldpc/lib/python3.8/site-packages/tensorflow/python/client/session.py:1455\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1454\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1457\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################################  Train  ####################################\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "for iter in range(0, iters_max, 1):\n",
    "    for i in range(0, num_of_batch, 1):\n",
    "        #ramdom choose Z with different probabilities\n",
    "        index = [0, 1, 2, 3, 0, 0]\n",
    "        Z_type = index[wordRandom.randint(0, 6)]\n",
    "        if Z_type == 0:\n",
    "            Z = 16\n",
    "            SNR_set = np.array([SNR_sigma[Z_type, iter]])\n",
    "            training_received_data, training_coded_bits = create_mix_epoch(SNR_set, wordRandom, noiseRandom, numOfWordSim_train,\n",
    "                                                                           code_n, code_k, Z,\n",
    "                                                                           Ldpc_GM[Z_type],\n",
    "                                                                           train_on_zero_word)\n",
    "            training_labels_for_mse = training_coded_bits\n",
    "            y_pred, train_loss, _ = sess.run(fetches=[net_dict[\"ya_output{0}\".format(iter)], net_dict[\"lossa{0}\".format(iter)],\n",
    "                                                      net_dict[\"train_stepa{0}\".format(iter)]],\n",
    "                                             feed_dict={xa: training_received_data, ya: training_labels_for_mse})\n",
    "            if i % 200 == 0:\n",
    "                print('iteration: [{0}/{1}]\\t'\n",
    "                      'epoch: [{2}/{3}]\\t'\n",
    "                      'loss: {4}\\t'.format(\n",
    "                    iter + 1, iters_max, i, num_of_batch, train_loss))\n",
    "\n",
    "        elif Z_type == 1:\n",
    "            Z = 3\n",
    "            SNR_set = np.array([SNR_sigma[Z_type, iter]])\n",
    "            training_received_data, training_coded_bits = create_mix_epoch(SNR_set, wordRandom, noiseRandom, numOfWordSim_train,\n",
    "                                                                           code_n, code_k, Z,\n",
    "                                                                           Ldpc_GM[Z_type],\n",
    "                                                                           train_on_zero_word)\n",
    "            training_labels_for_mse = training_coded_bits\n",
    "            y_pred, train_loss, _ = sess.run(fetches=[net_dict[\"yb_output{0}\".format(iter)], net_dict[\"lossb{0}\".format(iter)],\n",
    "                                                      net_dict[\"train_stepb{0}\".format(iter)]],\n",
    "                                             feed_dict={xb: training_received_data, yb: training_labels_for_mse})\n",
    "            if i % 200 == 0:\n",
    "                print('iteration: [{0}/{1}]\\t'\n",
    "                      'epoch: [{2}/{3}]\\t'\n",
    "                      'loss: {4}\\t'.format(\n",
    "                    iter + 1, iters_max, i, num_of_batch, train_loss))\n",
    "\n",
    "        elif Z_type == 2:\n",
    "            Z = 10\n",
    "            SNR_set = np.array([SNR_sigma[Z_type, iter]])\n",
    "            training_received_data, training_coded_bits = create_mix_epoch(SNR_set, wordRandom, noiseRandom, numOfWordSim_train,\n",
    "                                                                            code_n, code_k, Z,\n",
    "                                                                            Ldpc_GM[Z_type],\n",
    "                                                                            train_on_zero_word)\n",
    "            training_labels_for_mse = training_coded_bits\n",
    "            y_pred, train_loss, _ = sess.run(fetches=[net_dict[\"yc_output{0}\".format(iter)], net_dict[\"lossc{0}\".format(iter)],\n",
    "                                                       net_dict[\"train_stepc{0}\".format(iter)]],\n",
    "                                              feed_dict={xc: training_received_data, yc: training_labels_for_mse})\n",
    "            if i % 200 == 0:\n",
    "                print('iteration: [{0}/{1}]\\t'\n",
    "                      'epoch: [{2}/{3}]\\t'\n",
    "                      'loss: {4}\\t'.format(\n",
    "                    iter + 1, iters_max, i, num_of_batch, train_loss))\n",
    "\n",
    "        else:\n",
    "            Z = 6\n",
    "            SNR_set = np.array([SNR_sigma[Z_type, iter]])\n",
    "            training_received_data, training_coded_bits = create_mix_epoch(SNR_set, wordRandom, noiseRandom, numOfWordSim_train,\n",
    "                                                                            code_n, code_k, Z,\n",
    "                                                                           Ldpc_GM[Z_type],\n",
    "                                                                            train_on_zero_word)\n",
    "            training_labels_for_mse = training_coded_bits\n",
    "            y_pred, train_loss, _ = sess.run(fetches=[net_dict[\"yd_output{0}\".format(iter)], net_dict[\"lossd{0}\".format(iter)],\n",
    "                                                       net_dict[\"train_stepd{0}\".format(iter)]],\n",
    "                                              feed_dict={xd: training_received_data, yd: training_labels_for_mse})\n",
    "            if i % 200 == 0:\n",
    "                print('iteration: [{0}/{1}]\\t'\n",
    "                      'epoch: [{2}/{3}]\\t'\n",
    "                      'loss: {4}\\t'.format(\n",
    "                    iter + 1, iters_max, i, num_of_batch, train_loss))\n",
    "\n",
    "    ##################################  save weights and biases  ####################################\n",
    "    a, b = sess.run(fetches=[net_dict[\"Weights_Var{0}\".format(iter)], net_dict[\"Biases_Var{0}\".format(iter)]])\n",
    "    np.savetxt('./Weights_Var/Weights_Var{0}.txt'.format(iter), a, fmt='%s', delimiter=',')\n",
    "    np.savetxt('./Biases_Var/Biases_Var{0}.txt'.format(iter), b, fmt='%s', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_dict"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa4fb37e",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "{'Weights_Var0':         <tf.Variable 'Weights_Var:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var0':          <tf.Variable 'Biases_Var:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var1':         <tf.Variable 'Weights_Var_1:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var1':          <tf.Variable 'Biases_Var_1:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var2':         <tf.Variable 'Weights_Var_2:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var2':          <tf.Variable 'Biases_Var_2:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var3':         <tf.Variable 'Weights_Var_3:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var3':          <tf.Variable 'Biases_Var_3:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var4':         <tf.Variable 'Weights_Var_4:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var4':          <tf.Variable 'Biases_Var_4:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var5':         <tf.Variable 'Weights_Var_5:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var5':          <tf.Variable 'Biases_Var_5:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var6':         <tf.Variable 'Weights_Var_6:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var6':          <tf.Variable 'Biases_Var_6:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var7':         <tf.Variable 'Weights_Var_7:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var7':          <tf.Variable 'Biases_Var_7:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var8':         <tf.Variable 'Weights_Var_8:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var8':          <tf.Variable 'Biases_Var_8:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var9':         <tf.Variable 'Weights_Var_9:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var9':          <tf.Variable 'Biases_Var_9:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var10':        <tf.Variable 'Weights_Var_10:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var10':         <tf.Variable 'Biases_Var_10:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var11':        <tf.Variable 'Weights_Var_11:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var11':         <tf.Variable 'Biases_Var_11:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var12':        <tf.Variable 'Weights_Var_12:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var12':         <tf.Variable 'Biases_Var_12:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var13':        <tf.Variable 'Weights_Var_13:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var13':         <tf.Variable 'Biases_Var_13:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var14':        <tf.Variable 'Weights_Var_14:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var14':         <tf.Variable 'Biases_Var_14:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var15':        <tf.Variable 'Weights_Var_15:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var15':         <tf.Variable 'Biases_Var_15:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var16':        <tf.Variable 'Weights_Var_16:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var16':         <tf.Variable 'Biases_Var_16:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var17':        <tf.Variable 'Weights_Var_17:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var17':         <tf.Variable 'Biases_Var_17:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var18':        <tf.Variable 'Weights_Var_18:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var18':         <tf.Variable 'Biases_Var_18:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var19':        <tf.Variable 'Weights_Var_19:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var19':         <tf.Variable 'Biases_Var_19:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var20':        <tf.Variable 'Weights_Var_20:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var20':         <tf.Variable 'Biases_Var_20:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var21':        <tf.Variable 'Weights_Var_21:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var21':         <tf.Variable 'Biases_Var_21:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var22':        <tf.Variable 'Weights_Var_22:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var22':         <tf.Variable 'Biases_Var_22:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var23':        <tf.Variable 'Weights_Var_23:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var23':         <tf.Variable 'Biases_Var_23:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Weights_Var24':        <tf.Variable 'Weights_Var_24:0' shape=(197,) dtype=float32_ref>,\n",
    " 'Biases_Var24':         <tf.Variable 'Biases_Var_24:0' shape=(197,) dtype=float32_ref>,\n",
    " 'LLRa0':                <tf.Tensor 'zeros:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'LLRa1':                <tf.Tensor 'Mul_6:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output0':           <tf.Tensor 'ya_output:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa0':               <tf.Tensor 'mul_7:0' shape=() dtype=float32>,\n",
    " 'train_stepa0':         <tf.Operation 'Adam' type=NoOp>,\n",
    " 'LLRa2':                <tf.Tensor 'Mul_14:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output1':           <tf.Tensor 'ya_output_1:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa1':               <tf.Tensor 'mul_15:0' shape=() dtype=float32>,\n",
    " 'train_stepa1':         <tf.Operation 'Adam_1' type=NoOp>,\n",
    " 'LLRa3':                <tf.Tensor 'Mul_22:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output2':           <tf.Tensor 'ya_output_2:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa2':               <tf.Tensor 'mul_23:0' shape=() dtype=float32>,\n",
    " 'train_stepa2':         <tf.Operation 'Adam_2' type=NoOp>,\n",
    " 'LLRa4':                <tf.Tensor 'Mul_30:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output3':           <tf.Tensor 'ya_output_3:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa3':         <tf.Tensor 'mul_31:0' shape=() dtype=float32>,\n",
    " 'train_stepa3':         <tf.Operation 'Adam_3' type=NoOp>,\n",
    " 'LLRa5':        <tf.Tensor 'Mul_38:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output4':         <tf.Tensor 'ya_output_4:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa4':         <tf.Tensor 'mul_39:0' shape=() dtype=float32>,\n",
    " 'train_stepa4':         <tf.Operation 'Adam_4' type=NoOp>,\n",
    " 'LLRa6':        <tf.Tensor 'Mul_46:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output5':         <tf.Tensor 'ya_output_5:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa5':         <tf.Tensor 'mul_47:0' shape=() dtype=float32>,\n",
    " 'train_stepa5':         <tf.Operation 'Adam_5' type=NoOp>,\n",
    " 'LLRa7':        <tf.Tensor 'Mul_54:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output6':         <tf.Tensor 'ya_output_6:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa6':         <tf.Tensor 'mul_55:0' shape=() dtype=float32>,\n",
    " 'train_stepa6':         <tf.Operation 'Adam_6' type=NoOp>,\n",
    " 'LLRa8':        <tf.Tensor 'Mul_62:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output7':         <tf.Tensor 'ya_output_7:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa7':         <tf.Tensor 'mul_63:0' shape=() dtype=float32>,\n",
    " 'train_stepa7':         <tf.Operation 'Adam_7' type=NoOp>,\n",
    " 'LLRa9':        <tf.Tensor 'Mul_70:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output8':         <tf.Tensor 'ya_output_8:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa8':         <tf.Tensor 'mul_71:0' shape=() dtype=float32>,\n",
    " 'train_stepa8':         <tf.Operation 'Adam_8' type=NoOp>,\n",
    " 'LLRa10':         <tf.Tensor 'Mul_78:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output9':         <tf.Tensor 'ya_output_9:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa9':         <tf.Tensor 'mul_79:0' shape=() dtype=float32>,\n",
    " 'train_stepa9':         <tf.Operation 'Adam_9' type=NoOp>,\n",
    " 'LLRa11':         <tf.Tensor 'Mul_86:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output10':        <tf.Tensor 'ya_output_10:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa10':        <tf.Tensor 'mul_87:0' shape=() dtype=float32>,\n",
    " 'train_stepa10':        <tf.Operation 'Adam_10' type=NoOp>,\n",
    " 'LLRa12':         <tf.Tensor 'Mul_94:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output11':        <tf.Tensor 'ya_output_11:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa11':        <tf.Tensor 'mul_95:0' shape=() dtype=float32>,\n",
    " 'train_stepa11':        <tf.Operation 'Adam_11' type=NoOp>,\n",
    " 'LLRa13':         <tf.Tensor 'Mul_102:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output12':        <tf.Tensor 'ya_output_12:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa12':        <tf.Tensor 'mul_103:0' shape=() dtype=float32>,\n",
    " 'train_stepa12':        <tf.Operation 'Adam_12' type=NoOp>,\n",
    " 'LLRa14':         <tf.Tensor 'Mul_110:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output13':        <tf.Tensor 'ya_output_13:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa13':        <tf.Tensor 'mul_111:0' shape=() dtype=float32>,\n",
    " 'train_stepa13':        <tf.Operation 'Adam_13' type=NoOp>,\n",
    " 'LLRa15':         <tf.Tensor 'Mul_118:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output14':        <tf.Tensor 'ya_output_14:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa14':        <tf.Tensor 'mul_119:0' shape=() dtype=float32>,\n",
    " 'train_stepa14':        <tf.Operation 'Adam_14' type=NoOp>,\n",
    " 'LLRa16':         <tf.Tensor 'Mul_126:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output15':        <tf.Tensor 'ya_output_15:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa15':        <tf.Tensor 'mul_127:0' shape=() dtype=float32>,\n",
    " 'train_stepa15':        <tf.Operation 'Adam_15' type=NoOp>,\n",
    " 'LLRa17':         <tf.Tensor 'Mul_134:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output16':        <tf.Tensor 'ya_output_16:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa16':        <tf.Tensor 'mul_135:0' shape=() dtype=float32>,\n",
    " 'train_stepa16':        <tf.Operation 'Adam_16' type=NoOp>,\n",
    " 'LLRa18':         <tf.Tensor 'Mul_142:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output17':        <tf.Tensor 'ya_output_17:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa17':        <tf.Tensor 'mul_143:0' shape=() dtype=float32>,\n",
    " 'train_stepa17':        <tf.Operation 'Adam_17' type=NoOp>,\n",
    " 'LLRa19':         <tf.Tensor 'Mul_150:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output18':        <tf.Tensor 'ya_output_18:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa18':        <tf.Tensor 'mul_151:0' shape=() dtype=float32>,\n",
    " 'train_stepa18':        <tf.Operation 'Adam_18' type=NoOp>,\n",
    " 'LLRa20':         <tf.Tensor 'Mul_158:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output19':        <tf.Tensor 'ya_output_19:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa19':        <tf.Tensor 'mul_159:0' shape=() dtype=float32>,\n",
    " 'train_stepa19':        <tf.Operation 'Adam_19' type=NoOp>,\n",
    " 'LLRa21':         <tf.Tensor 'Mul_166:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output20':        <tf.Tensor 'ya_output_20:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa20':        <tf.Tensor 'mul_167:0' shape=() dtype=float32>,\n",
    " 'train_stepa20':        <tf.Operation 'Adam_20' type=NoOp>,\n",
    " 'LLRa22':         <tf.Tensor 'Mul_174:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output21':        <tf.Tensor 'ya_output_21:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa21':        <tf.Tensor 'mul_175:0' shape=() dtype=float32>,\n",
    " 'train_stepa21':        <tf.Operation 'Adam_21' type=NoOp>,\n",
    " 'LLRa23':         <tf.Tensor 'Mul_182:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output22':        <tf.Tensor 'ya_output_22:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa22':        <tf.Tensor 'mul_183:0' shape=() dtype=float32>,\n",
    " 'train_stepa22':        <tf.Operation 'Adam_22' type=NoOp>,\n",
    " 'LLRa24':         <tf.Tensor 'Mul_190:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output23':        <tf.Tensor 'ya_output_23:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa23':        <tf.Tensor 'mul_191:0' shape=() dtype=float32>,\n",
    " 'train_stepa23':        <tf.Operation 'Adam_23' type=NoOp>,\n",
    " 'LLRa25':         <tf.Tensor 'Mul_198:0' shape=(50, 16, 197) dtype=float32>,\n",
    " 'ya_output24':        <tf.Tensor 'ya_output_24:0' shape=(50, 832) dtype=float32>,\n",
    " 'lossa24':        <tf.Tensor 'mul_199:0' shape=() dtype=float32>,\n",
    " 'train_stepa24':        <tf.Operation 'Adam_24' type=NoOp>,\n",
    " 'LLRb0':        <tf.Tensor 'zeros_26:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'LLRb1':        <tf.Tensor 'Mul_206:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output0':         <tf.Tensor 'yb_output:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb0':         <tf.Tensor 'mul_207:0' shape=() dtype=float32>,\n",
    " 'train_stepb0':         <tf.Operation 'Adam_25' type=NoOp>,\n",
    " 'LLRb2':        <tf.Tensor 'Mul_214:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output1':         <tf.Tensor 'yb_output_1:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb1':         <tf.Tensor 'mul_215:0' shape=() dtype=float32>,\n",
    " 'train_stepb1':         <tf.Operation 'Adam_26' type=NoOp>,\n",
    " 'LLRb3':        <tf.Tensor 'Mul_222:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output2':         <tf.Tensor 'yb_output_2:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb2':         <tf.Tensor 'mul_223:0' shape=() dtype=float32>,\n",
    " 'train_stepb2':         <tf.Operation 'Adam_27' type=NoOp>,\n",
    " 'LLRb4':        <tf.Tensor 'Mul_230:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output3':         <tf.Tensor 'yb_output_3:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb3':         <tf.Tensor 'mul_231:0' shape=() dtype=float32>,\n",
    " 'train_stepb3':         <tf.Operation 'Adam_28' type=NoOp>,\n",
    " 'LLRb5':        <tf.Tensor 'Mul_238:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output4':         <tf.Tensor 'yb_output_4:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb4':         <tf.Tensor 'mul_239:0' shape=() dtype=float32>,\n",
    " 'train_stepb4':         <tf.Operation 'Adam_29' type=NoOp>,\n",
    " 'LLRb6':        <tf.Tensor 'Mul_246:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output5':         <tf.Tensor 'yb_output_5:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb5':         <tf.Tensor 'mul_247:0' shape=() dtype=float32>,\n",
    " 'train_stepb5':         <tf.Operation 'Adam_30' type=NoOp>,\n",
    " 'LLRb7':        <tf.Tensor 'Mul_254:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output6':         <tf.Tensor 'yb_output_6:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb6':         <tf.Tensor 'mul_255:0' shape=() dtype=float32>,\n",
    " 'train_stepb6':         <tf.Operation 'Adam_31' type=NoOp>,\n",
    " 'LLRb8':        <tf.Tensor 'Mul_262:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output7':         <tf.Tensor 'yb_output_7:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb7':         <tf.Tensor 'mul_263:0' shape=() dtype=float32>,\n",
    " 'train_stepb7':         <tf.Operation 'Adam_32' type=NoOp>,\n",
    " 'LLRb9':        <tf.Tensor 'Mul_270:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output8':         <tf.Tensor 'yb_output_8:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb8':         <tf.Tensor 'mul_271:0' shape=() dtype=float32>,\n",
    " 'train_stepb8':         <tf.Operation 'Adam_33' type=NoOp>,\n",
    " 'LLRb10':         <tf.Tensor 'Mul_278:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output9':         <tf.Tensor 'yb_output_9:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb9':         <tf.Tensor 'mul_279:0' shape=() dtype=float32>,\n",
    " 'train_stepb9':         <tf.Operation 'Adam_34' type=NoOp>,\n",
    " 'LLRb11':         <tf.Tensor 'Mul_286:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output10':        <tf.Tensor 'yb_output_10:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb10':        <tf.Tensor 'mul_287:0' shape=() dtype=float32>,\n",
    " 'train_stepb10':        <tf.Operation 'Adam_35' type=NoOp>,\n",
    " 'LLRb12':         <tf.Tensor 'Mul_294:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output11':        <tf.Tensor 'yb_output_11:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb11':        <tf.Tensor 'mul_295:0' shape=() dtype=float32>,\n",
    " 'train_stepb11':        <tf.Operation 'Adam_36' type=NoOp>,\n",
    " 'LLRb13':         <tf.Tensor 'Mul_302:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output12':        <tf.Tensor 'yb_output_12:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb12':        <tf.Tensor 'mul_303:0' shape=() dtype=float32>,\n",
    " 'train_stepb12':        <tf.Operation 'Adam_37' type=NoOp>,\n",
    " 'LLRb14':         <tf.Tensor 'Mul_310:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output13':        <tf.Tensor 'yb_output_13:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb13':        <tf.Tensor 'mul_311:0' shape=() dtype=float32>,\n",
    " 'train_stepb13':        <tf.Operation 'Adam_38' type=NoOp>,\n",
    " 'LLRb15':         <tf.Tensor 'Mul_318:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output14':        <tf.Tensor 'yb_output_14:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb14':        <tf.Tensor 'mul_319:0' shape=() dtype=float32>,\n",
    " 'train_stepb14':        <tf.Operation 'Adam_39' type=NoOp>,\n",
    " 'LLRb16':         <tf.Tensor 'Mul_326:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output15':        <tf.Tensor 'yb_output_15:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb15':        <tf.Tensor 'mul_327:0' shape=() dtype=float32>,\n",
    " 'train_stepb15':        <tf.Operation 'Adam_40' type=NoOp>,\n",
    " 'LLRb17':         <tf.Tensor 'Mul_334:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output16':        <tf.Tensor 'yb_output_16:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb16':        <tf.Tensor 'mul_335:0' shape=() dtype=float32>,\n",
    " 'train_stepb16':        <tf.Operation 'Adam_41' type=NoOp>,\n",
    " 'LLRb18':         <tf.Tensor 'Mul_342:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output17':        <tf.Tensor 'yb_output_17:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb17':        <tf.Tensor 'mul_343:0' shape=() dtype=float32>,\n",
    " 'train_stepb17':        <tf.Operation 'Adam_42' type=NoOp>,\n",
    " 'LLRb19':         <tf.Tensor 'Mul_350:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output18':        <tf.Tensor 'yb_output_18:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb18':        <tf.Tensor 'mul_351:0' shape=() dtype=float32>,\n",
    " 'train_stepb18':        <tf.Operation 'Adam_43' type=NoOp>,\n",
    " 'LLRb20':         <tf.Tensor 'Mul_358:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output19':        <tf.Tensor 'yb_output_19:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb19':        <tf.Tensor 'mul_359:0' shape=() dtype=float32>,\n",
    " 'train_stepb19':        <tf.Operation 'Adam_44' type=NoOp>,\n",
    " 'LLRb21':         <tf.Tensor 'Mul_366:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output20':        <tf.Tensor 'yb_output_20:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb20':        <tf.Tensor 'mul_367:0' shape=() dtype=float32>,\n",
    " 'train_stepb20':        <tf.Operation 'Adam_45' type=NoOp>,\n",
    " 'LLRb22':         <tf.Tensor 'Mul_374:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output21':        <tf.Tensor 'yb_output_21:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb21':        <tf.Tensor 'mul_375:0' shape=() dtype=float32>,\n",
    " 'train_stepb21':        <tf.Operation 'Adam_46' type=NoOp>,\n",
    " 'LLRb23':         <tf.Tensor 'Mul_382:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output22':        <tf.Tensor 'yb_output_22:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb22':        <tf.Tensor 'mul_383:0' shape=() dtype=float32>,\n",
    " 'train_stepb22':        <tf.Operation 'Adam_47' type=NoOp>,\n",
    " 'LLRb24':         <tf.Tensor 'Mul_390:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output23':        <tf.Tensor 'yb_output_23:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb23':        <tf.Tensor 'mul_391:0' shape=() dtype=float32>,\n",
    " 'train_stepb23':        <tf.Operation 'Adam_48' type=NoOp>,\n",
    " 'LLRb25':         <tf.Tensor 'Mul_398:0' shape=(50, 3, 197) dtype=float32>,\n",
    " 'yb_output24':        <tf.Tensor 'yb_output_24:0' shape=(50, 156) dtype=float32>,\n",
    " 'lossb24':        <tf.Tensor 'mul_399:0' shape=() dtype=float32>,\n",
    " 'train_stepb24':        <tf.Operation 'Adam_49' type=NoOp>,\n",
    " 'LLRc0':        <tf.Tensor 'zeros_52:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'LLRc1':        <tf.Tensor 'Mul_406:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output0':         <tf.Tensor 'yc_output:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc0':         <tf.Tensor 'mul_407:0' shape=() dtype=float32>,\n",
    " 'train_stepc0':         <tf.Operation 'Adam_50' type=NoOp>,\n",
    " 'LLRc2':        <tf.Tensor 'Mul_414:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output1':         <tf.Tensor 'yc_output_1:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc1':         <tf.Tensor 'mul_415:0' shape=() dtype=float32>,\n",
    " 'train_stepc1':         <tf.Operation 'Adam_51' type=NoOp>,\n",
    " 'LLRc3':        <tf.Tensor 'Mul_422:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output2':         <tf.Tensor 'yc_output_2:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc2':         <tf.Tensor 'mul_423:0' shape=() dtype=float32>,\n",
    " 'train_stepc2':         <tf.Operation 'Adam_52' type=NoOp>,\n",
    " 'LLRc4':        <tf.Tensor 'Mul_430:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output3':         <tf.Tensor 'yc_output_3:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc3':         <tf.Tensor 'mul_431:0' shape=() dtype=float32>,\n",
    " 'train_stepc3':         <tf.Operation 'Adam_53' type=NoOp>,\n",
    " 'LLRc5':        <tf.Tensor 'Mul_438:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output4':         <tf.Tensor 'yc_output_4:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc4':         <tf.Tensor 'mul_439:0' shape=() dtype=float32>,\n",
    " 'train_stepc4':         <tf.Operation 'Adam_54' type=NoOp>,\n",
    " 'LLRc6':        <tf.Tensor 'Mul_446:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output5':         <tf.Tensor 'yc_output_5:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc5':         <tf.Tensor 'mul_447:0' shape=() dtype=float32>,\n",
    " 'train_stepc5':         <tf.Operation 'Adam_55' type=NoOp>,\n",
    " 'LLRc7':        <tf.Tensor 'Mul_454:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output6':         <tf.Tensor 'yc_output_6:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc6':         <tf.Tensor 'mul_455:0' shape=() dtype=float32>,\n",
    " 'train_stepc6':         <tf.Operation 'Adam_56' type=NoOp>,\n",
    " 'LLRc8':        <tf.Tensor 'Mul_462:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output7':         <tf.Tensor 'yc_output_7:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc7':         <tf.Tensor 'mul_463:0' shape=() dtype=float32>,\n",
    " 'train_stepc7':         <tf.Operation 'Adam_57' type=NoOp>,\n",
    " 'LLRc9':        <tf.Tensor 'Mul_470:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output8':         <tf.Tensor 'yc_output_8:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc8':         <tf.Tensor 'mul_471:0' shape=() dtype=float32>,\n",
    " 'train_stepc8':         <tf.Operation 'Adam_58' type=NoOp>,\n",
    " 'LLRc10':         <tf.Tensor 'Mul_478:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output9':         <tf.Tensor 'yc_output_9:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc9':         <tf.Tensor 'mul_479:0' shape=() dtype=float32>,\n",
    " 'train_stepc9':         <tf.Operation 'Adam_59' type=NoOp>,\n",
    " 'LLRc11':         <tf.Tensor 'Mul_486:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output10':        <tf.Tensor 'yc_output_10:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc10':        <tf.Tensor 'mul_487:0' shape=() dtype=float32>,\n",
    " 'train_stepc10':        <tf.Operation 'Adam_60' type=NoOp>,\n",
    " 'LLRc12':         <tf.Tensor 'Mul_494:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output11':        <tf.Tensor 'yc_output_11:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc11':        <tf.Tensor 'mul_495:0' shape=() dtype=float32>,\n",
    " 'train_stepc11':        <tf.Operation 'Adam_61' type=NoOp>,\n",
    " 'LLRc13':         <tf.Tensor 'Mul_502:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output12':        <tf.Tensor 'yc_output_12:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc12':        <tf.Tensor 'mul_503:0' shape=() dtype=float32>,\n",
    " 'train_stepc12':        <tf.Operation 'Adam_62' type=NoOp>,\n",
    " 'LLRc14':         <tf.Tensor 'Mul_510:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output13':        <tf.Tensor 'yc_output_13:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc13':        <tf.Tensor 'mul_511:0' shape=() dtype=float32>,\n",
    " 'train_stepc13':        <tf.Operation 'Adam_63' type=NoOp>,\n",
    " 'LLRc15':         <tf.Tensor 'Mul_518:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output14':        <tf.Tensor 'yc_output_14:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc14':        <tf.Tensor 'mul_519:0' shape=() dtype=float32>,\n",
    " 'train_stepc14':        <tf.Operation 'Adam_64' type=NoOp>,\n",
    " 'LLRc16':         <tf.Tensor 'Mul_526:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output15':        <tf.Tensor 'yc_output_15:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc15':        <tf.Tensor 'mul_527:0' shape=() dtype=float32>,\n",
    " 'train_stepc15':        <tf.Operation 'Adam_65' type=NoOp>,\n",
    " 'LLRc17':         <tf.Tensor 'Mul_534:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output16':        <tf.Tensor 'yc_output_16:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc16':        <tf.Tensor 'mul_535:0' shape=() dtype=float32>,\n",
    " 'train_stepc16':        <tf.Operation 'Adam_66' type=NoOp>,\n",
    " 'LLRc18':         <tf.Tensor 'Mul_542:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output17':        <tf.Tensor 'yc_output_17:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc17':        <tf.Tensor 'mul_543:0' shape=() dtype=float32>,\n",
    " 'train_stepc17':        <tf.Operation 'Adam_67' type=NoOp>,\n",
    " 'LLRc19':         <tf.Tensor 'Mul_550:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output18':        <tf.Tensor 'yc_output_18:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc18':        <tf.Tensor 'mul_551:0' shape=() dtype=float32>,\n",
    " 'train_stepc18':        <tf.Operation 'Adam_68' type=NoOp>,\n",
    " 'LLRc20':         <tf.Tensor 'Mul_558:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output19':        <tf.Tensor 'yc_output_19:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc19':        <tf.Tensor 'mul_559:0' shape=() dtype=float32>,\n",
    " 'train_stepc19':        <tf.Operation 'Adam_69' type=NoOp>,\n",
    " 'LLRc21':         <tf.Tensor 'Mul_566:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output20':        <tf.Tensor 'yc_output_20:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc20':        <tf.Tensor 'mul_567:0' shape=() dtype=float32>,\n",
    " 'train_stepc20':        <tf.Operation 'Adam_70' type=NoOp>,\n",
    " 'LLRc22':         <tf.Tensor 'Mul_574:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output21':        <tf.Tensor 'yc_output_21:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc21':        <tf.Tensor 'mul_575:0' shape=() dtype=float32>,\n",
    " 'train_stepc21':        <tf.Operation 'Adam_71' type=NoOp>,\n",
    " 'LLRc23':         <tf.Tensor 'Mul_582:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output22':        <tf.Tensor 'yc_output_22:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc22':        <tf.Tensor 'mul_583:0' shape=() dtype=float32>,\n",
    " 'train_stepc22':        <tf.Operation 'Adam_72' type=NoOp>,\n",
    " 'LLRc24':         <tf.Tensor 'Mul_590:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output23':        <tf.Tensor 'yc_output_23:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc23':        <tf.Tensor 'mul_591:0' shape=() dtype=float32>,\n",
    " 'train_stepc23':        <tf.Operation 'Adam_73' type=NoOp>,\n",
    " 'LLRc25':         <tf.Tensor 'Mul_598:0' shape=(50, 10, 197) dtype=float32>,\n",
    " 'yc_output24':        <tf.Tensor 'yc_output_24:0' shape=(50, 520) dtype=float32>,\n",
    " 'lossc24':        <tf.Tensor 'mul_599:0' shape=() dtype=float32>,\n",
    " 'train_stepc24':        <tf.Operation 'Adam_74' type=NoOp>,\n",
    " 'LLRd0':        <tf.Tensor 'zeros_78:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'LLRd1':        <tf.Tensor 'Mul_606:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output0':         <tf.Tensor 'yd_output:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd0':         <tf.Tensor 'mul_607:0' shape=() dtype=float32>,\n",
    " 'train_stepd0':         <tf.Operation 'Adam_75' type=NoOp>,\n",
    " 'LLRd2':        <tf.Tensor 'Mul_614:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output1':         <tf.Tensor 'yd_output_1:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd1':         <tf.Tensor 'mul_615:0' shape=() dtype=float32>,\n",
    " 'train_stepd1':         <tf.Operation 'Adam_76' type=NoOp>,\n",
    " 'LLRd3':        <tf.Tensor 'Mul_622:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output2':         <tf.Tensor 'yd_output_2:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd2':         <tf.Tensor 'mul_623:0' shape=() dtype=float32>,\n",
    " 'train_stepd2':         <tf.Operation 'Adam_77' type=NoOp>,\n",
    " 'LLRd4':        <tf.Tensor 'Mul_630:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output3':         <tf.Tensor 'yd_output_3:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd3':         <tf.Tensor 'mul_631:0' shape=() dtype=float32>,\n",
    " 'train_stepd3':         <tf.Operation 'Adam_78' type=NoOp>,\n",
    " 'LLRd5':        <tf.Tensor 'Mul_638:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output4':         <tf.Tensor 'yd_output_4:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd4':         <tf.Tensor 'mul_639:0' shape=() dtype=float32>,\n",
    " 'train_stepd4':         <tf.Operation 'Adam_79' type=NoOp>,\n",
    " 'LLRd6':        <tf.Tensor 'Mul_646:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output5':         <tf.Tensor 'yd_output_5:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd5':         <tf.Tensor 'mul_647:0' shape=() dtype=float32>,\n",
    " 'train_stepd5':         <tf.Operation 'Adam_80' type=NoOp>,\n",
    " 'LLRd7':        <tf.Tensor 'Mul_654:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output6':         <tf.Tensor 'yd_output_6:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd6':         <tf.Tensor 'mul_655:0' shape=() dtype=float32>,\n",
    " 'train_stepd6':         <tf.Operation 'Adam_81' type=NoOp>,\n",
    " 'LLRd8':        <tf.Tensor 'Mul_662:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output7':         <tf.Tensor 'yd_output_7:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd7':         <tf.Tensor 'mul_663:0' shape=() dtype=float32>,\n",
    " 'train_stepd7':         <tf.Operation 'Adam_82' type=NoOp>,\n",
    " 'LLRd9':        <tf.Tensor 'Mul_670:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output8':         <tf.Tensor 'yd_output_8:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd8':         <tf.Tensor 'mul_671:0' shape=() dtype=float32>,\n",
    " 'train_stepd8':         <tf.Operation 'Adam_83' type=NoOp>,\n",
    " 'LLRd10':         <tf.Tensor 'Mul_678:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output9':         <tf.Tensor 'yd_output_9:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd9':         <tf.Tensor 'mul_679:0' shape=() dtype=float32>,\n",
    " 'train_stepd9':         <tf.Operation 'Adam_84' type=NoOp>,\n",
    " 'LLRd11':         <tf.Tensor 'Mul_686:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output10':        <tf.Tensor 'yd_output_10:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd10':        <tf.Tensor 'mul_687:0' shape=() dtype=float32>,\n",
    " 'train_stepd10':        <tf.Operation 'Adam_85' type=NoOp>,\n",
    " 'LLRd12':         <tf.Tensor 'Mul_694:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output11':        <tf.Tensor 'yd_output_11:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd11':        <tf.Tensor 'mul_695:0' shape=() dtype=float32>,\n",
    " 'train_stepd11':        <tf.Operation 'Adam_86' type=NoOp>,\n",
    " 'LLRd13':         <tf.Tensor 'Mul_702:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output12':        <tf.Tensor 'yd_output_12:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd12':        <tf.Tensor 'mul_703:0' shape=() dtype=float32>,\n",
    " 'train_stepd12':        <tf.Operation 'Adam_87' type=NoOp>,\n",
    " 'LLRd14':         <tf.Tensor 'Mul_710:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output13':        <tf.Tensor 'yd_output_13:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd13':        <tf.Tensor 'mul_711:0' shape=() dtype=float32>,\n",
    " 'train_stepd13':        <tf.Operation 'Adam_88' type=NoOp>,\n",
    " 'LLRd15':         <tf.Tensor 'Mul_718:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output14':        <tf.Tensor 'yd_output_14:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd14':        <tf.Tensor 'mul_719:0' shape=() dtype=float32>,\n",
    " 'train_stepd14':        <tf.Operation 'Adam_89' type=NoOp>,\n",
    " 'LLRd16':         <tf.Tensor 'Mul_726:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output15':        <tf.Tensor 'yd_output_15:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd15':        <tf.Tensor 'mul_727:0' shape=() dtype=float32>,\n",
    " 'train_stepd15':        <tf.Operation 'Adam_90' type=NoOp>,\n",
    " 'LLRd17':         <tf.Tensor 'Mul_734:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output16':        <tf.Tensor 'yd_output_16:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd16':        <tf.Tensor 'mul_735:0' shape=() dtype=float32>,\n",
    " 'train_stepd16':        <tf.Operation 'Adam_91' type=NoOp>,\n",
    " 'LLRd18':         <tf.Tensor 'Mul_742:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output17':        <tf.Tensor 'yd_output_17:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd17':        <tf.Tensor 'mul_743:0' shape=() dtype=float32>,\n",
    " 'train_stepd17':        <tf.Operation 'Adam_92' type=NoOp>,\n",
    " 'LLRd19':         <tf.Tensor 'Mul_750:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output18':        <tf.Tensor 'yd_output_18:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd18':        <tf.Tensor 'mul_751:0' shape=() dtype=float32>,\n",
    " 'train_stepd18':        <tf.Operation 'Adam_93' type=NoOp>,\n",
    " 'LLRd20':         <tf.Tensor 'Mul_758:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output19':        <tf.Tensor 'yd_output_19:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd19':        <tf.Tensor 'mul_759:0' shape=() dtype=float32>,\n",
    " 'train_stepd19':        <tf.Operation 'Adam_94' type=NoOp>,\n",
    " 'LLRd21':         <tf.Tensor 'Mul_766:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output20':        <tf.Tensor 'yd_output_20:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd20':        <tf.Tensor 'mul_767:0' shape=() dtype=float32>,\n",
    " 'train_stepd20':        <tf.Operation 'Adam_95' type=NoOp>,\n",
    " 'LLRd22':         <tf.Tensor 'Mul_774:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output21':        <tf.Tensor 'yd_output_21:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd21':        <tf.Tensor 'mul_775:0' shape=() dtype=float32>,\n",
    " 'train_stepd21':        <tf.Operation 'Adam_96' type=NoOp>,\n",
    " 'LLRd23':         <tf.Tensor 'Mul_782:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output22':        <tf.Tensor 'yd_output_22:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd22':        <tf.Tensor 'mul_783:0' shape=() dtype=float32>,\n",
    " 'train_stepd22':        <tf.Operation 'Adam_97' type=NoOp>,\n",
    " 'LLRd24':         <tf.Tensor 'Mul_790:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output23':        <tf.Tensor 'yd_output_23:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd23':        <tf.Tensor 'mul_791:0' shape=() dtype=float32>,\n",
    " 'train_stepd23':        <tf.Operation 'Adam_98' type=NoOp>,\n",
    " 'LLRd25':         <tf.Tensor 'Mul_798:0' shape=(50, 6, 197) dtype=float32>,\n",
    " 'yd_output24':        <tf.Tensor 'yd_output_24:0' shape=(50, 312) dtype=float32>,\n",
    " 'lossd24':        <tf.Tensor 'mul_799:0' shape=() dtype=float32>,\n",
    " 'train_stepd24':        <tf.Operation 'Adam_99' type=NoOp>}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a43178",
   "metadata": {},
   "source": [
    "## Net Dict\n",
    "\n",
    "| Name | Content |\n",
    "| :-: | :-- |\n",
    "| Weights_Var0..24  | <tf.Variable 'Weights_Var:0..24' shape=(197,) dtype=float32_ref> |\n",
    "| Biases_Var0..24 | <tf.Variable 'Biases_Var:0..24' shape=(197,) dtype=float32_ref> |\n",
    "\n",
    "### A\n",
    "| Name | Content |\n",
    "| :-: | :-- |\n",
    "| LLRa0 | <tf.Tensor 'zeros:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| LLRa1 | <tf.Tensor 'Mul_6:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output0  | <tf.Tensor 'ya_output:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa0  | <tf.Tensor 'mul_7:0' shape=() dtype=float32> |\n",
    "| train_stepa0  | <tf.Operation 'Adam' type=NoOp> |\n",
    "| LLRa2 | <tf.Tensor 'Mul_14:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output1  | <tf.Tensor 'ya_output_1:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa1  | <tf.Tensor 'mul_15:0' shape=() dtype=float32> |\n",
    "| train_stepa1  | <tf.Operation 'Adam_1' type=NoOp> |\n",
    "| LLRa3 | <tf.Tensor 'Mul_22:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output2  | <tf.Tensor 'ya_output_2:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa2  | <tf.Tensor 'mul_23:0' shape=() dtype=float32> |\n",
    "| train_stepa2  | <tf.Operation 'Adam_2' type=NoOp> |\n",
    "| LLRa4 | <tf.Tensor 'Mul_30:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output3  | <tf.Tensor 'ya_output_3:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa3  | <tf.Tensor 'mul_31:0' shape=() dtype=float32> |\n",
    "| train_stepa3  | <tf.Operation 'Adam_3' type=NoOp> |\n",
    "| LLRa5 | <tf.Tensor 'Mul_38:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output4  | <tf.Tensor 'ya_output_4:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa4  | <tf.Tensor 'mul_39:0' shape=() dtype=float32> |\n",
    "| train_stepa4  | <tf.Operation 'Adam_4' type=NoOp> |\n",
    "| LLRa6 | <tf.Tensor 'Mul_46:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output5  | <tf.Tensor 'ya_output_5:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa5  | <tf.Tensor 'mul_47:0' shape=() dtype=float32> |\n",
    "| train_stepa5  | <tf.Operation 'Adam_5' type=NoOp> |\n",
    "| LLRa7 | <tf.Tensor 'Mul_54:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output6  | <tf.Tensor 'ya_output_6:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa6  | <tf.Tensor 'mul_55:0' shape=() dtype=float32> |\n",
    "| train_stepa6  | <tf.Operation 'Adam_6' type=NoOp> |\n",
    "| LLRa8 | <tf.Tensor 'Mul_62:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output7  | <tf.Tensor 'ya_output_7:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa7  | <tf.Tensor 'mul_63:0' shape=() dtype=float32> |\n",
    "| train_stepa7  | <tf.Operation 'Adam_7' type=NoOp> |\n",
    "| LLRa9 | <tf.Tensor 'Mul_70:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output8  | <tf.Tensor 'ya_output_8:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa8  | <tf.Tensor 'mul_71:0' shape=() dtype=float32> |\n",
    "| train_stepa8  | <tf.Operation 'Adam_8' type=NoOp> |\n",
    "| LLRa10  | <tf.Tensor 'Mul_78:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output9  | <tf.Tensor 'ya_output_9:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa9  | <tf.Tensor 'mul_79:0' shape=() dtype=float32> |\n",
    "| train_stepa9  | <tf.Operation 'Adam_9' type=NoOp> |\n",
    "| LLRa11  | <tf.Tensor 'Mul_86:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output10 | <tf.Tensor 'ya_output_10:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa10 | <tf.Tensor 'mul_87:0' shape=() dtype=float32> |\n",
    "| train_stepa10 | <tf.Operation 'Adam_10' type=NoOp> |\n",
    "| LLRa12  | <tf.Tensor 'Mul_94:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output11 | <tf.Tensor 'ya_output_11:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa11 | <tf.Tensor 'mul_95:0' shape=() dtype=float32> |\n",
    "| train_stepa11 | <tf.Operation 'Adam_11' type=NoOp> |\n",
    "| LLRa13  | <tf.Tensor 'Mul_102:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output12 | <tf.Tensor 'ya_output_12:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa12 | <tf.Tensor 'mul_103:0' shape=() dtype=float32> |\n",
    "| train_stepa12 | <tf.Operation 'Adam_12' type=NoOp> |\n",
    "| LLRa14  | <tf.Tensor 'Mul_110:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output13 | <tf.Tensor 'ya_output_13:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa13 | <tf.Tensor 'mul_111:0' shape=() dtype=float32> |\n",
    "| train_stepa13 | <tf.Operation 'Adam_13' type=NoOp> |\n",
    "| LLRa15  | <tf.Tensor 'Mul_118:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output14 | <tf.Tensor 'ya_output_14:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa14 | <tf.Tensor 'mul_119:0' shape=() dtype=float32> |\n",
    "| train_stepa14 | <tf.Operation 'Adam_14' type=NoOp> |\n",
    "| LLRa16  | <tf.Tensor 'Mul_126:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output15 | <tf.Tensor 'ya_output_15:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa15 | <tf.Tensor 'mul_127:0' shape=() dtype=float32> |\n",
    "| train_stepa15 | <tf.Operation 'Adam_15' type=NoOp> |\n",
    "| LLRa17  | <tf.Tensor 'Mul_134:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output16 | <tf.Tensor 'ya_output_16:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa16 | <tf.Tensor 'mul_135:0' shape=() dtype=float32> |\n",
    "| train_stepa16 | <tf.Operation 'Adam_16' type=NoOp> |\n",
    "| LLRa18  | <tf.Tensor 'Mul_142:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output17 | <tf.Tensor 'ya_output_17:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa17 | <tf.Tensor 'mul_143:0' shape=() dtype=float32> |\n",
    "| train_stepa17 | <tf.Operation 'Adam_17' type=NoOp> |\n",
    "| LLRa19  | <tf.Tensor 'Mul_150:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output18 | <tf.Tensor 'ya_output_18:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa18 | <tf.Tensor 'mul_151:0' shape=() dtype=float32> |\n",
    "| train_stepa18 | <tf.Operation 'Adam_18' type=NoOp> |\n",
    "| LLRa20  | <tf.Tensor 'Mul_158:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output19 | <tf.Tensor 'ya_output_19:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa19 | <tf.Tensor 'mul_159:0' shape=() dtype=float32> |\n",
    "| train_stepa19 | <tf.Operation 'Adam_19' type=NoOp> |\n",
    "| LLRa21  | <tf.Tensor 'Mul_166:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output20 | <tf.Tensor 'ya_output_20:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa20 | <tf.Tensor 'mul_167:0' shape=() dtype=float32> |\n",
    "| train_stepa20 | <tf.Operation 'Adam_20' type=NoOp> |\n",
    "| LLRa22  | <tf.Tensor 'Mul_174:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output21 | <tf.Tensor 'ya_output_21:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa21 | <tf.Tensor 'mul_175:0' shape=() dtype=float32> |\n",
    "| train_stepa21 | <tf.Operation 'Adam_21' type=NoOp> |\n",
    "| LLRa23  | <tf.Tensor 'Mul_182:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output22 | <tf.Tensor 'ya_output_22:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa22 | <tf.Tensor 'mul_183:0' shape=() dtype=float32> |\n",
    "| train_stepa22 | <tf.Operation 'Adam_22' type=NoOp> |\n",
    "| LLRa24  | <tf.Tensor 'Mul_190:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output23 | <tf.Tensor 'ya_output_23:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa23 | <tf.Tensor 'mul_191:0' shape=() dtype=float32> |\n",
    "| train_stepa23 | <tf.Operation 'Adam_23' type=NoOp> |\n",
    "| LLRa25  | <tf.Tensor 'Mul_198:0' shape=(50, 16, 197) dtype=float32> |\n",
    "| ya_output24 | <tf.Tensor 'ya_output_24:0' shape=(50, 832) dtype=float32> |\n",
    "| lossa24 | <tf.Tensor 'mul_199:0' shape=() dtype=float32> |\n",
    "| train_stepa24 | <tf.Operation 'Adam_24' type=NoOp> |\n",
    "\n",
    "## B\n",
    "| Name | Content |\n",
    "| :-: | :-- |\n",
    "| LLRb0 | <tf.Tensor 'zeros_26:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| LLRb1 | <tf.Tensor 'Mul_206:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output0  | <tf.Tensor 'yb_output:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb0  | <tf.Tensor 'mul_207:0' shape=() dtype=float32> |\n",
    "| train_stepb0  | <tf.Operation 'Adam_25' type=NoOp> |\n",
    "| LLRb2 | <tf.Tensor 'Mul_214:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output1  | <tf.Tensor 'yb_output_1:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb1  | <tf.Tensor 'mul_215:0' shape=() dtype=float32> |\n",
    "| train_stepb1  | <tf.Operation 'Adam_26' type=NoOp> |\n",
    "| LLRb3 | <tf.Tensor 'Mul_222:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output2  | <tf.Tensor 'yb_output_2:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb2  | <tf.Tensor 'mul_223:0' shape=() dtype=float32> |\n",
    "| train_stepb2  | <tf.Operation 'Adam_27' type=NoOp> |\n",
    "| LLRb4 | <tf.Tensor 'Mul_230:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output3  | <tf.Tensor 'yb_output_3:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb3  | <tf.Tensor 'mul_231:0' shape=() dtype=float32> |\n",
    "| train_stepb3  | <tf.Operation 'Adam_28' type=NoOp> |\n",
    "| LLRb5 | <tf.Tensor 'Mul_238:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output4  | <tf.Tensor 'yb_output_4:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb4  | <tf.Tensor 'mul_239:0' shape=() dtype=float32> |\n",
    "| train_stepb4  | <tf.Operation 'Adam_29' type=NoOp> |\n",
    "| LLRb6 | <tf.Tensor 'Mul_246:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output5  | <tf.Tensor 'yb_output_5:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb5  | <tf.Tensor 'mul_247:0' shape=() dtype=float32> |\n",
    "| train_stepb5  | <tf.Operation 'Adam_30' type=NoOp> |\n",
    "| LLRb7 | <tf.Tensor 'Mul_254:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output6  | <tf.Tensor 'yb_output_6:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb6  | <tf.Tensor 'mul_255:0' shape=() dtype=float32> |\n",
    "| train_stepb6  | <tf.Operation 'Adam_31' type=NoOp> |\n",
    "| LLRb8 | <tf.Tensor 'Mul_262:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output7  | <tf.Tensor 'yb_output_7:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb7  | <tf.Tensor 'mul_263:0' shape=() dtype=float32> |\n",
    "| train_stepb7  | <tf.Operation 'Adam_32' type=NoOp> |\n",
    "| LLRb9 | <tf.Tensor 'Mul_270:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output8  | <tf.Tensor 'yb_output_8:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb8  | <tf.Tensor 'mul_271:0' shape=() dtype=float32> |\n",
    "| train_stepb8  | <tf.Operation 'Adam_33' type=NoOp> |\n",
    "| LLRb10  | <tf.Tensor 'Mul_278:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output9  | <tf.Tensor 'yb_output_9:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb9  | <tf.Tensor 'mul_279:0' shape=() dtype=float32> |\n",
    "| train_stepb9  | <tf.Operation 'Adam_34' type=NoOp> |\n",
    "| LLRb11  | <tf.Tensor 'Mul_286:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output10 | <tf.Tensor 'yb_output_10:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb10 | <tf.Tensor 'mul_287:0' shape=() dtype=float32> |\n",
    "| train_stepb10 | <tf.Operation 'Adam_35' type=NoOp> |\n",
    "| LLRb12  | <tf.Tensor 'Mul_294:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output11 | <tf.Tensor 'yb_output_11:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb11 | <tf.Tensor 'mul_295:0' shape=() dtype=float32> |\n",
    "| train_stepb11 | <tf.Operation 'Adam_36' type=NoOp> |\n",
    "| LLRb13  | <tf.Tensor 'Mul_302:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output12 | <tf.Tensor 'yb_output_12:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb12 | <tf.Tensor 'mul_303:0' shape=() dtype=float32> |\n",
    "| train_stepb12 | <tf.Operation 'Adam_37' type=NoOp> |\n",
    "| LLRb14  | <tf.Tensor 'Mul_310:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output13 | <tf.Tensor 'yb_output_13:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb13 | <tf.Tensor 'mul_311:0' shape=() dtype=float32> |\n",
    "| train_stepb13 | <tf.Operation 'Adam_38' type=NoOp> |\n",
    "| LLRb15  | <tf.Tensor 'Mul_318:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output14 | <tf.Tensor 'yb_output_14:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb14 | <tf.Tensor 'mul_319:0' shape=() dtype=float32> |\n",
    "| train_stepb14 | <tf.Operation 'Adam_39' type=NoOp> |\n",
    "| LLRb16  | <tf.Tensor 'Mul_326:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output15 | <tf.Tensor 'yb_output_15:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb15 | <tf.Tensor 'mul_327:0' shape=() dtype=float32> |\n",
    "| train_stepb15 | <tf.Operation 'Adam_40' type=NoOp> |\n",
    "| LLRb17  | <tf.Tensor 'Mul_334:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output16 | <tf.Tensor 'yb_output_16:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb16 | <tf.Tensor 'mul_335:0' shape=() dtype=float32> |\n",
    "| train_stepb16 | <tf.Operation 'Adam_41' type=NoOp> |\n",
    "| LLRb18  | <tf.Tensor 'Mul_342:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output17 | <tf.Tensor 'yb_output_17:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb17 | <tf.Tensor 'mul_343:0' shape=() dtype=float32> |\n",
    "| train_stepb17 | <tf.Operation 'Adam_42' type=NoOp> |\n",
    "| LLRb19  | <tf.Tensor 'Mul_350:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output18 | <tf.Tensor 'yb_output_18:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb18 | <tf.Tensor 'mul_351:0' shape=() dtype=float32> |\n",
    "| train_stepb18 | <tf.Operation 'Adam_43' type=NoOp> |\n",
    "| LLRb20  | <tf.Tensor 'Mul_358:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output19 | <tf.Tensor 'yb_output_19:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb19 | <tf.Tensor 'mul_359:0' shape=() dtype=float32> |\n",
    "| train_stepb19 | <tf.Operation 'Adam_44' type=NoOp> |\n",
    "| LLRb21  | <tf.Tensor 'Mul_366:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output20 | <tf.Tensor 'yb_output_20:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb20 | <tf.Tensor 'mul_367:0' shape=() dtype=float32> |\n",
    "| train_stepb20 | <tf.Operation 'Adam_45' type=NoOp> |\n",
    "| LLRb22  | <tf.Tensor 'Mul_374:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output21 | <tf.Tensor 'yb_output_21:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb21 | <tf.Tensor 'mul_375:0' shape=() dtype=float32> |\n",
    "| train_stepb21 | <tf.Operation 'Adam_46' type=NoOp> |\n",
    "| LLRb23  | <tf.Tensor 'Mul_382:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output22 | <tf.Tensor 'yb_output_22:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb22 | <tf.Tensor 'mul_383:0' shape=() dtype=float32> |\n",
    "| train_stepb22 | <tf.Operation 'Adam_47' type=NoOp> |\n",
    "| LLRb24  | <tf.Tensor 'Mul_390:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output23 | <tf.Tensor 'yb_output_23:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb23 | <tf.Tensor 'mul_391:0' shape=() dtype=float32> |\n",
    "| train_stepb23 | <tf.Operation 'Adam_48' type=NoOp> |\n",
    "| LLRb25  | <tf.Tensor 'Mul_398:0' shape=(50, 3, 197) dtype=float32> |\n",
    "| yb_output24 | <tf.Tensor 'yb_output_24:0' shape=(50, 156) dtype=float32> |\n",
    "| lossb24 | <tf.Tensor 'mul_399:0' shape=() dtype=float32> |\n",
    "| train_stepb24 | <tf.Operation 'Adam_49' type=NoOp> |\n",
    "\n",
    "## C\n",
    "| Name | Content |\n",
    "| :-: | :-- |\n",
    "| LLRc0 | <tf.Tensor 'zeros_52:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| LLRc1 | <tf.Tensor 'Mul_406:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output0  | <tf.Tensor 'yc_output:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc0  | <tf.Tensor 'mul_407:0' shape=() dtype=float32> |\n",
    "| train_stepc0  | <tf.Operation 'Adam_50' type=NoOp> |\n",
    "| LLRc2 | <tf.Tensor 'Mul_414:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output1  | <tf.Tensor 'yc_output_1:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc1  | <tf.Tensor 'mul_415:0' shape=() dtype=float32> |\n",
    "| train_stepc1  | <tf.Operation 'Adam_51' type=NoOp> |\n",
    "| LLRc3 | <tf.Tensor 'Mul_422:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output2  | <tf.Tensor 'yc_output_2:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc2  | <tf.Tensor 'mul_423:0' shape=() dtype=float32> |\n",
    "| train_stepc2  | <tf.Operation 'Adam_52' type=NoOp> |\n",
    "| LLRc4 | <tf.Tensor 'Mul_430:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output3  | <tf.Tensor 'yc_output_3:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc3  | <tf.Tensor 'mul_431:0' shape=() dtype=float32> |\n",
    "| train_stepc3  | <tf.Operation 'Adam_53' type=NoOp> |\n",
    "| LLRc5 | <tf.Tensor 'Mul_438:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output4  | <tf.Tensor 'yc_output_4:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc4  | <tf.Tensor 'mul_439:0' shape=() dtype=float32> |\n",
    "| train_stepc4  | <tf.Operation 'Adam_54' type=NoOp> |\n",
    "| LLRc6 | <tf.Tensor 'Mul_446:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output5  | <tf.Tensor 'yc_output_5:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc5  | <tf.Tensor 'mul_447:0' shape=() dtype=float32> |\n",
    "| train_stepc5  | <tf.Operation 'Adam_55' type=NoOp> |\n",
    "| LLRc7 | <tf.Tensor 'Mul_454:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output6  | <tf.Tensor 'yc_output_6:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc6  | <tf.Tensor 'mul_455:0' shape=() dtype=float32> |\n",
    "| train_stepc6  | <tf.Operation 'Adam_56' type=NoOp> |\n",
    "| LLRc8 | <tf.Tensor 'Mul_462:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output7  | <tf.Tensor 'yc_output_7:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc7  | <tf.Tensor 'mul_463:0' shape=() dtype=float32> |\n",
    "| train_stepc7  | <tf.Operation 'Adam_57' type=NoOp> |\n",
    "| LLRc9 | <tf.Tensor 'Mul_470:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output8  | <tf.Tensor 'yc_output_8:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc8  | <tf.Tensor 'mul_471:0' shape=() dtype=float32> |\n",
    "| train_stepc8  | <tf.Operation 'Adam_58' type=NoOp> |\n",
    "| LLRc10  | <tf.Tensor 'Mul_478:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output9  | <tf.Tensor 'yc_output_9:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc9  | <tf.Tensor 'mul_479:0' shape=() dtype=float32> |\n",
    "| train_stepc9  | <tf.Operation 'Adam_59' type=NoOp> |\n",
    "| LLRc11  | <tf.Tensor 'Mul_486:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output10 | <tf.Tensor 'yc_output_10:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc10 | <tf.Tensor 'mul_487:0' shape=() dtype=float32> |\n",
    "| train_stepc10 | <tf.Operation 'Adam_60' type=NoOp> |\n",
    "| LLRc12  | <tf.Tensor 'Mul_494:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output11 | <tf.Tensor 'yc_output_11:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc11 | <tf.Tensor 'mul_495:0' shape=() dtype=float32> |\n",
    "| train_stepc11 | <tf.Operation 'Adam_61' type=NoOp> |\n",
    "| LLRc13  | <tf.Tensor 'Mul_502:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output12 | <tf.Tensor 'yc_output_12:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc12 | <tf.Tensor 'mul_503:0' shape=() dtype=float32> |\n",
    "| train_stepc12 | <tf.Operation 'Adam_62' type=NoOp> |\n",
    "| LLRc14  | <tf.Tensor 'Mul_510:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output13 | <tf.Tensor 'yc_output_13:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc13 | <tf.Tensor 'mul_511:0' shape=() dtype=float32> |\n",
    "| train_stepc13 | <tf.Operation 'Adam_63' type=NoOp> |\n",
    "| LLRc15  | <tf.Tensor 'Mul_518:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output14 | <tf.Tensor 'yc_output_14:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc14 | <tf.Tensor 'mul_519:0' shape=() dtype=float32> |\n",
    "| train_stepc14 | <tf.Operation 'Adam_64' type=NoOp> |\n",
    "| LLRc16  | <tf.Tensor 'Mul_526:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output15 | <tf.Tensor 'yc_output_15:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc15 | <tf.Tensor 'mul_527:0' shape=() dtype=float32> |\n",
    "| train_stepc15 | <tf.Operation 'Adam_65' type=NoOp> |\n",
    "| LLRc17  | <tf.Tensor 'Mul_534:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output16 | <tf.Tensor 'yc_output_16:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc16 | <tf.Tensor 'mul_535:0' shape=() dtype=float32> |\n",
    "| train_stepc16 | <tf.Operation 'Adam_66' type=NoOp> |\n",
    "| LLRc18  | <tf.Tensor 'Mul_542:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output17 | <tf.Tensor 'yc_output_17:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc17 | <tf.Tensor 'mul_543:0' shape=() dtype=float32> |\n",
    "| train_stepc17 | <tf.Operation 'Adam_67' type=NoOp> |\n",
    "| LLRc19  | <tf.Tensor 'Mul_550:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output18 | <tf.Tensor 'yc_output_18:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc18 | <tf.Tensor 'mul_551:0' shape=() dtype=float32> |\n",
    "| train_stepc18 | <tf.Operation 'Adam_68' type=NoOp> |\n",
    "| LLRc20  | <tf.Tensor 'Mul_558:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output19 | <tf.Tensor 'yc_output_19:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc19 | <tf.Tensor 'mul_559:0' shape=() dtype=float32> |\n",
    "| train_stepc19 | <tf.Operation 'Adam_69' type=NoOp> |\n",
    "| LLRc21  | <tf.Tensor 'Mul_566:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output20 | <tf.Tensor 'yc_output_20:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc20 | <tf.Tensor 'mul_567:0' shape=() dtype=float32> |\n",
    "| train_stepc20 | <tf.Operation 'Adam_70' type=NoOp> |\n",
    "| LLRc22  | <tf.Tensor 'Mul_574:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output21 | <tf.Tensor 'yc_output_21:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc21 | <tf.Tensor 'mul_575:0' shape=() dtype=float32> |\n",
    "| train_stepc21 | <tf.Operation 'Adam_71' type=NoOp> |\n",
    "| LLRc23  | <tf.Tensor 'Mul_582:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output22 | <tf.Tensor 'yc_output_22:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc22 | <tf.Tensor 'mul_583:0' shape=() dtype=float32> |\n",
    "| train_stepc22 | <tf.Operation 'Adam_72' type=NoOp> |\n",
    "| LLRc24  | <tf.Tensor 'Mul_590:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output23 | <tf.Tensor 'yc_output_23:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc23 | <tf.Tensor 'mul_591:0' shape=() dtype=float32> |\n",
    "| train_stepc23 | <tf.Operation 'Adam_73' type=NoOp> |\n",
    "| LLRc25  | <tf.Tensor 'Mul_598:0' shape=(50, 10, 197) dtype=float32> |\n",
    "| yc_output24 | <tf.Tensor 'yc_output_24:0' shape=(50, 520) dtype=float32> |\n",
    "| lossc24 | <tf.Tensor 'mul_599:0' shape=() dtype=float32> |\n",
    "| train_stepc24 | <tf.Operation 'Adam_74' type=NoOp> |\n",
    "\n",
    "## D\n",
    "| Name | Content |\n",
    "| :-: | :-- |\n",
    "| LLRd0 | <tf.Tensor 'zeros_78:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| LLRd1 | <tf.Tensor 'Mul_606:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output0  | <tf.Tensor 'yd_output:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd0  | <tf.Tensor 'mul_607:0' shape=() dtype=float32> |\n",
    "| train_stepd0  | <tf.Operation 'Adam_75' type=NoOp> |\n",
    "| LLRd2 | <tf.Tensor 'Mul_614:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output1  | <tf.Tensor 'yd_output_1:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd1  | <tf.Tensor 'mul_615:0' shape=() dtype=float32> |\n",
    "| train_stepd1  | <tf.Operation 'Adam_76' type=NoOp> |\n",
    "| LLRd3 | <tf.Tensor 'Mul_622:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output2  | <tf.Tensor 'yd_output_2:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd2  | <tf.Tensor 'mul_623:0' shape=() dtype=float32> |\n",
    "| train_stepd2  | <tf.Operation 'Adam_77' type=NoOp> |\n",
    "| LLRd4 | <tf.Tensor 'Mul_630:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output3  | <tf.Tensor 'yd_output_3:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd3  | <tf.Tensor 'mul_631:0' shape=() dtype=float32> |\n",
    "| train_stepd3  | <tf.Operation 'Adam_78' type=NoOp> |\n",
    "| LLRd5 | <tf.Tensor 'Mul_638:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output4  | <tf.Tensor 'yd_output_4:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd4  | <tf.Tensor 'mul_639:0' shape=() dtype=float32> |\n",
    "| train_stepd4  | <tf.Operation 'Adam_79' type=NoOp> |\n",
    "| LLRd6 | <tf.Tensor 'Mul_646:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output5  | <tf.Tensor 'yd_output_5:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd5  | <tf.Tensor 'mul_647:0' shape=() dtype=float32> |\n",
    "| train_stepd5  | <tf.Operation 'Adam_80' type=NoOp> |\n",
    "| LLRd7 | <tf.Tensor 'Mul_654:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output6  | <tf.Tensor 'yd_output_6:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd6  | <tf.Tensor 'mul_655:0' shape=() dtype=float32> |\n",
    "| train_stepd6  | <tf.Operation 'Adam_81' type=NoOp> |\n",
    "| LLRd8 | <tf.Tensor 'Mul_662:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output7  | <tf.Tensor 'yd_output_7:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd7  | <tf.Tensor 'mul_663:0' shape=() dtype=float32> |\n",
    "| train_stepd7  | <tf.Operation 'Adam_82' type=NoOp> |\n",
    "| LLRd9 | <tf.Tensor 'Mul_670:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output8  | <tf.Tensor 'yd_output_8:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd8  | <tf.Tensor 'mul_671:0' shape=() dtype=float32> |\n",
    "| train_stepd8  | <tf.Operation 'Adam_83' type=NoOp> |\n",
    "| LLRd10  | <tf.Tensor 'Mul_678:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output9  | <tf.Tensor 'yd_output_9:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd9  | <tf.Tensor 'mul_679:0' shape=() dtype=float32> |\n",
    "| train_stepd9  | <tf.Operation 'Adam_84' type=NoOp> |\n",
    "| LLRd11  | <tf.Tensor 'Mul_686:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output10 | <tf.Tensor 'yd_output_10:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd10 | <tf.Tensor 'mul_687:0' shape=() dtype=float32> |\n",
    "| train_stepd10 | <tf.Operation 'Adam_85' type=NoOp> |\n",
    "| LLRd12  | <tf.Tensor 'Mul_694:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output11 | <tf.Tensor 'yd_output_11:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd11 | <tf.Tensor 'mul_695:0' shape=() dtype=float32> |\n",
    "| train_stepd11 | <tf.Operation 'Adam_86' type=NoOp> |\n",
    "| LLRd13  | <tf.Tensor 'Mul_702:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output12 | <tf.Tensor 'yd_output_12:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd12 | <tf.Tensor 'mul_703:0' shape=() dtype=float32> |\n",
    "| train_stepd12 | <tf.Operation 'Adam_87' type=NoOp> |\n",
    "| LLRd14  | <tf.Tensor 'Mul_710:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output13 | <tf.Tensor 'yd_output_13:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd13 | <tf.Tensor 'mul_711:0' shape=() dtype=float32> |\n",
    "| train_stepd13 | <tf.Operation 'Adam_88' type=NoOp> |\n",
    "| LLRd15  | <tf.Tensor 'Mul_718:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output14 | <tf.Tensor 'yd_output_14:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd14 | <tf.Tensor 'mul_719:0' shape=() dtype=float32> |\n",
    "| train_stepd14 | <tf.Operation 'Adam_89' type=NoOp> |\n",
    "| LLRd16  | <tf.Tensor 'Mul_726:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output15 | <tf.Tensor 'yd_output_15:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd15 | <tf.Tensor 'mul_727:0' shape=() dtype=float32> |\n",
    "| train_stepd15 | <tf.Operation 'Adam_90' type=NoOp> |\n",
    "| LLRd17  | <tf.Tensor 'Mul_734:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output16 | <tf.Tensor 'yd_output_16:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd16 | <tf.Tensor 'mul_735:0' shape=() dtype=float32> |\n",
    "| train_stepd16 | <tf.Operation 'Adam_91' type=NoOp> |\n",
    "| LLRd18  | <tf.Tensor 'Mul_742:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output17 | <tf.Tensor 'yd_output_17:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd17 | <tf.Tensor 'mul_743:0' shape=() dtype=float32> |\n",
    "| train_stepd17 | <tf.Operation 'Adam_92' type=NoOp> |\n",
    "| LLRd19  | <tf.Tensor 'Mul_750:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output18 | <tf.Tensor 'yd_output_18:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd18 | <tf.Tensor 'mul_751:0' shape=() dtype=float32> |\n",
    "| train_stepd18 | <tf.Operation 'Adam_93' type=NoOp> |\n",
    "| LLRd20  | <tf.Tensor 'Mul_758:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output19 | <tf.Tensor 'yd_output_19:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd19 | <tf.Tensor 'mul_759:0' shape=() dtype=float32> |\n",
    "| train_stepd19 | <tf.Operation 'Adam_94' type=NoOp> |\n",
    "| LLRd21  | <tf.Tensor 'Mul_766:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output20 | <tf.Tensor 'yd_output_20:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd20 | <tf.Tensor 'mul_767:0' shape=() dtype=float32> |\n",
    "| train_stepd20 | <tf.Operation 'Adam_95' type=NoOp> |\n",
    "| LLRd22  | <tf.Tensor 'Mul_774:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output21 | <tf.Tensor 'yd_output_21:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd21 | <tf.Tensor 'mul_775:0' shape=() dtype=float32> |\n",
    "| train_stepd21 | <tf.Operation 'Adam_96' type=NoOp> |\n",
    "| LLRd23  | <tf.Tensor 'Mul_782:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output22 | <tf.Tensor 'yd_output_22:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd22 | <tf.Tensor 'mul_783:0' shape=() dtype=float32> |\n",
    "| train_stepd22 | <tf.Operation 'Adam_97' type=NoOp> |\n",
    "| LLRd24  | <tf.Tensor 'Mul_790:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output23 | <tf.Tensor 'yd_output_23:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd23 | <tf.Tensor 'mul_791:0' shape=() dtype=float32> |\n",
    "| train_stepd23 | <tf.Operation 'Adam_98' type=NoOp> |\n",
    "| LLRd25  | <tf.Tensor 'Mul_798:0' shape=(50, 6, 197) dtype=float32> |\n",
    "| yd_output24 | <tf.Tensor 'yd_output_24:0' shape=(50, 312) dtype=float32> |\n",
    "| lossd24 | <tf.Tensor 'mul_799:0' shape=() dtype=float32> |\n",
    "| train_stepd24 | <tf.Operation 'Adam_99' type=NoOp> |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9bccc6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jsac-ldpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
